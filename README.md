# Deep learning model for approximating the COSMIC functional size based on use-case names

This repository contains a replication package for the paper entitled "Deep learning model for end-to-end approximation of COSMIC functional size based on use-case names" submitted to the Information and Software Technology journal.

It contains a dataset of names of use cases and their functional size expressed in COSMIC. Due to confidentiality restrictions, we publish the names of use cases after tokenization (and removal of stop words). However, the replication package contains the code that was used to produce the dataset from the original data.

In order to run the code you need the installation of Python 3 (with jupyter notebook) and R. You can find the dependencies in the notebooks. The most important are: numpy, pandas, sklearn, gensim, spacy, tensorflow, keras, matplotlib.

## Pre-trained word embeddings

We used the 3rd-party pre-trained word embeddings that are not included in the repository. You can obtain the necessary files from these sites:
- https://github.com/3Top/word2vec-api
- https://github.com/vefstathiou/SO_word2vec

In order to run the code, you need to modify the path to a folder containing word embeddings in the file paths.py

## The strcuture of the repository

We included the following files/folders in the replication package:
- Try DEEP-COSMIC-UC on your use cases.ipynb - if you want to train and run the model for your use cases
- paths.py - contains paths to folders
- helpers.py - some reusable functions
- /input/use-cases.csv - contains the names of use cases (tokenized and cleared from stop words and some symbols) and their COSMIC size
- /input/use-cases-uctype.csv - contains data required by AUCG and BN-UCGAIN to predict types of use cases
- /input/verbs.csv - list of verbs in use-case names
- /input/10-fold-train-full.csv - generated indices used for cross-validation (do not overwrite this file if you want to replicate the results)
- /input/10-fold-val-full.csv - generated indices used for cross-validation (do not overwrite this file if you want to replicate the results)
- /output/ - stores output files generated by the scripts
- Prepare a use-case dataset.ipynb - transforming the original use-case names to the dataset used in this study
- Dataset.ipynb - a summary of the dataset
- Word embeddings - convert GloVe to word2vec format.ipynb - notebook allowing to transform GloVe embeddings so they can be loaded by the gensim library
-  Selecting the model architecture.ipynb - selecting the model architecture and optimizing the hyperparameters
- Word embeddings.ipynb - analysis of word embeddings
- Validation - AUC.ipynb - the accuracy of the AUC model
- Validation - AUCG and BN-UCGAIN.ipynb - the accuracy of AUCG and BN-UCGAIN models (code in R)
- Validation - DEEP-COSMIC-UC.ipynb - the accuracy of the proposed model
- Validation - Random Guessing.ipynb - the accuracy of random guessing
- Validation - Summary of the results.ipynb - the comparison of the accuracy of the models

