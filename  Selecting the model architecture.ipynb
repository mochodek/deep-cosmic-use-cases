{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we select the model to be further studied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\ml\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\user\\Anaconda3\\envs\\ml\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "\n",
    "import talos as ta\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from paths import input_folder, output_folder, word_embeddings_folder\n",
    "\n",
    "from helpers import create_embedding_matrix, tokens2index, texts2index_padded\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import gc\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.layers import TimeDistributed, GlobalMaxPooling1D, GlobalAveragePooling1D, Activation, Input, LSTM, GRU, Dense, Dropout, Flatten, Embedding, SpatialDropout1D, Bidirectional, CuDNNGRU\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Flatten, concatenate\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, activations\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from keras.engine import InputSpec\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import set_random_seed\n",
    "from keras import backend as K\n",
    "\n",
    "# This part required only for GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "random_seed = 102329"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProjectID</th>\n",
       "      <th>UC</th>\n",
       "      <th>TransTypes</th>\n",
       "      <th>UCType</th>\n",
       "      <th>Cfp</th>\n",
       "      <th>TitleTokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P01</td>\n",
       "      <td>UC2-1-1</td>\n",
       "      <td>C|D|R|U</td>\n",
       "      <td>C|D|R|U</td>\n",
       "      <td>16</td>\n",
       "      <td>manage faculties crud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P01</td>\n",
       "      <td>UC2-1-10</td>\n",
       "      <td>DL|L|R</td>\n",
       "      <td>L</td>\n",
       "      <td>27</td>\n",
       "      <td>assign science olympiads major specialty edit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01</td>\n",
       "      <td>UC2-1-11</td>\n",
       "      <td>CS|R</td>\n",
       "      <td>CS</td>\n",
       "      <td>7</td>\n",
       "      <td>manage ranking algorithms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P01</td>\n",
       "      <td>UC2-1-13</td>\n",
       "      <td>C|D|R|U</td>\n",
       "      <td>C|D|R|U</td>\n",
       "      <td>17</td>\n",
       "      <td>manage exams crud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P01</td>\n",
       "      <td>UC2-1-14</td>\n",
       "      <td>DL|L|R</td>\n",
       "      <td>L</td>\n",
       "      <td>27</td>\n",
       "      <td>manage assignments exams majors specialties</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ProjectID        UC TransTypes   UCType  Cfp  \\\n",
       "0       P01   UC2-1-1    C|D|R|U  C|D|R|U   16   \n",
       "1       P01  UC2-1-10     DL|L|R        L   27   \n",
       "2       P01  UC2-1-11       CS|R       CS    7   \n",
       "3       P01  UC2-1-13    C|D|R|U  C|D|R|U   17   \n",
       "4       P01  UC2-1-14     DL|L|R        L   27   \n",
       "\n",
       "                                         TitleTokens  \n",
       "0                              manage faculties crud  \n",
       "1  assign science olympiads major specialty edit ...  \n",
       "2                          manage ranking algorithms  \n",
       "3                                  manage exams crud  \n",
       "4        manage assignments exams majors specialties  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cases_df = pd.read_csv(f\"{input_folder}use-cases.csv\", index_col=0)\n",
    "use_cases_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Google News word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = KeyedVectors.load_word2vec_format(f\"{word_embeddings_folder}SO_vectors_200.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare input data and embeddings matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use-case names has been already tokenized and stored in TitleTokens column. We need to split them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_names = [name.split(\" \") for name in use_cases_df['TitleTokens'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['manage', 'faculties', 'crud'],\n",
       " ['assign', 'science', 'olympiads', 'major', 'specialty', 'edit', 'delete'],\n",
       " ['manage', 'ranking', 'algorithms'],\n",
       " ['manage', 'exams', 'crud'],\n",
       " ['manage', 'assignments', 'exams', 'majors', 'specialties']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will prune the word embeddings model so it does not contain words that are not in the dataset to reduce the memory usage. Since we do not train the embeddings it does not affect the results in any way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens = list(set(list(itertools.chain.from_iterable(tokenized_names))))\n",
    "len(unique_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prune the wv model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_keep = unique_tokens\n",
    "words_to_trim = [w for w in wv.vocab.keys() if w not in words_to_keep]\n",
    "ids_to_trim = [wv.vocab[w].index for w in words_to_trim]\n",
    "\n",
    "for w in words_to_trim:\n",
    "    del wv.vocab[w]\n",
    "\n",
    "wv.vectors = np.delete(wv.vectors, ids_to_trim, axis=0)\n",
    "wv.init_sims(replace=True)\n",
    "\n",
    "for i in sorted(ids_to_trim, reverse=True):\n",
    "    del(wv.index2word[i])\n",
    "\n",
    "for i in range(len(wv.vocab.keys())):\n",
    "    word = wv.index2word[i]\n",
    "    wv.vocab[word].index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH, VECTOR_LENGTH = 16, wv.vector_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create embeddings matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 200)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = create_embedding_matrix(wv, VECTOR_LENGTH)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert use-case names to list of token identifiers from the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "''s' is not in the vocabulary - 'modify candidate 's payments'\n",
      "''s' is not in the vocabulary - 'view candidate 's data'\n",
      "''s' is not in the vocabulary - 'modify candidate 's data'\n",
      "''' is not in the vocabulary - 'view candidates ' ranking major specialization classification'\n",
      "''s' is not in the vocabulary - 'browse candidate 's events history'\n",
      "''s' is not in the vocabulary - 'creating customer 's representative information contacts'\n",
      "''s' is not in the vocabulary - 'modifying customer 's representative information contacts'\n",
      "''s' is not in the vocabulary - 'deleting customer 's representative information contacts'\n",
      "''' is not in the vocabulary - 'looking clients ' table'\n",
      "''s' is not in the vocabulary - 'view candidate 's data'\n",
      "'a' is not in the vocabulary - 'a quick search student archival grades'\n",
      "''s' is not in the vocabulary - 'view protocol 's status'\n",
      "''' is not in the vocabulary - 'inform assignment task ' outside system ''\n",
      "''' is not in the vocabulary - 'inform assignment task ' outside system ''\n",
      "'oek' is not in the vocabulary - 'bind kek oek'\n",
      "'oeks' is not in the vocabulary - 'report bindings oeks keks'\n",
      "'oek' is not in the vocabulary - 'add oek'\n",
      "'swdpi' is not in the vocabulary - 'notifications desktop swdpi system user dashboard'\n",
      "'e' is not in the vocabulary - 'define e mail template'\n",
      "''' is not in the vocabulary - 'view users ' opinions'\n",
      "''s' is not in the vocabulary - 'remove user 's opinion'\n",
      "''s' is not in the vocabulary - 'approve user 's opinion'\n",
      "''' is not in the vocabulary - 'view users ' payments'\n",
      "'b.' is not in the vocabulary - 'perform edit operation supply system b.'\n",
      "'a.' is not in the vocabulary - 'perform edit operation index system a.'\n",
      "'a.' is not in the vocabulary - 'perform editing operation order system a.'\n",
      "'b.' is not in the vocabulary - 'execute operation indices system b.'\n",
      "'b.' is not in the vocabulary - 'verify accept operation supply system b.'\n",
      "'a.' is not in the vocabulary - 'order execution verification operations supply system a.'\n",
      "'b.' is not in the vocabulary - 'order execution verification operations orders system b.'\n",
      "'b.' is not in the vocabulary - 'order execution operation indices system b.'\n",
      "'a.' is not in the vocabulary - 'preview index system a.'\n",
      "'a.' is not in the vocabulary - 'preview supplies system a.'\n"
     ]
    }
   ],
   "source": [
    "use_case_names_ids = texts2index_padded(tokenized_names, wv, seq_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([168, 429, 295,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_case_names_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = use_case_names_ids\n",
    "y = use_cases_df['Cfp'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial architecture selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step we analyze the key architectural decisions to be made - the choice of type of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_1l_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    MAX_SEQUENCE_LENGTH = x_train.shape[1]\n",
    "    \n",
    "    global embedding_matrix\n",
    "    \n",
    "    embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                     output_dim=embedding_matrix.shape[1],\n",
    "                     mask_zero=False,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=MAX_SEQUENCE_LENGTH,\n",
    "                     trainable=False)\n",
    "\n",
    "    line_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name=\"input\")\n",
    "    embedded_sequences = embedding_layer(line_input)\n",
    "    cnn = Conv1D(filters=params['filters_first'], kernel_size=params['kernel_size'], strides=1, \n",
    "                        padding=params['padding'],\n",
    "                        activation=params['activation'])(embedded_sequences)\n",
    "    cnn = AveragePooling1D(pool_size=2)(cnn)\n",
    "\n",
    "    cnn = Flatten()(cnn)\n",
    "\n",
    "    cnn = Dropout(params['dropout'])(cnn)\n",
    "\n",
    "    output = Dense(1, activation='linear')(cnn)\n",
    "\n",
    "    model = Model([line_input] , output) \n",
    "    \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.95, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=params['loss'],\n",
    "                  metrics=['mse', 'mae'])\n",
    "\n",
    "    callbacks_list = [\n",
    "        ReduceLROnPlateau( \n",
    "            monitor='loss',\n",
    "            min_lr=0.001,\n",
    "            factor=0.5,\n",
    "            verbose=1,\n",
    "            patience=10), \n",
    "    ]\n",
    "    \n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[x_val, y_val])\n",
    "    return out, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters_first':[4, 8, 16, 32],\n",
    "     'kernel_size':[3],\n",
    "     'batch_size': [64, 128, 256],\n",
    "     'epochs': [100, 300, 500],\n",
    "     'dropout': [0, 0.2, 0.5, 0.8],\n",
    "     'padding' : ['same',],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 144/144 [18:11<00:00,  6.69s/it]\n"
     ]
    }
   ],
   "source": [
    "h_cnn1 = ta.Scan(x, y, params=p,\n",
    "            model=get_cnn_1l_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn1 = ta.Reporting(h_cnn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn1.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}cnn1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters_first</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>padding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>500</td>\n",
       "      <td>3.726943</td>\n",
       "      <td>32.047591</td>\n",
       "      <td>3.726943</td>\n",
       "      <td>3.415188</td>\n",
       "      <td>31.368683</td>\n",
       "      <td>3.415188</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>500</td>\n",
       "      <td>3.729600</td>\n",
       "      <td>32.526435</td>\n",
       "      <td>3.729600</td>\n",
       "      <td>3.613402</td>\n",
       "      <td>33.080520</td>\n",
       "      <td>3.613402</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>500</td>\n",
       "      <td>3.736840</td>\n",
       "      <td>31.898237</td>\n",
       "      <td>3.736840</td>\n",
       "      <td>3.079919</td>\n",
       "      <td>25.045749</td>\n",
       "      <td>3.079919</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>500</td>\n",
       "      <td>3.746110</td>\n",
       "      <td>32.187851</td>\n",
       "      <td>3.746110</td>\n",
       "      <td>3.481493</td>\n",
       "      <td>31.267456</td>\n",
       "      <td>3.481493</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>300</td>\n",
       "      <td>3.748397</td>\n",
       "      <td>32.422323</td>\n",
       "      <td>3.748397</td>\n",
       "      <td>3.680381</td>\n",
       "      <td>32.974671</td>\n",
       "      <td>3.680381</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>300</td>\n",
       "      <td>3.750573</td>\n",
       "      <td>31.803752</td>\n",
       "      <td>3.750573</td>\n",
       "      <td>3.473694</td>\n",
       "      <td>31.426172</td>\n",
       "      <td>3.473694</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>300</td>\n",
       "      <td>3.752030</td>\n",
       "      <td>32.847059</td>\n",
       "      <td>3.752030</td>\n",
       "      <td>3.706009</td>\n",
       "      <td>34.045101</td>\n",
       "      <td>3.706009</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>300</td>\n",
       "      <td>3.753161</td>\n",
       "      <td>31.281720</td>\n",
       "      <td>3.753161</td>\n",
       "      <td>3.212223</td>\n",
       "      <td>25.569225</td>\n",
       "      <td>3.212223</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>500</td>\n",
       "      <td>3.753482</td>\n",
       "      <td>32.528194</td>\n",
       "      <td>3.753482</td>\n",
       "      <td>3.539890</td>\n",
       "      <td>31.543397</td>\n",
       "      <td>3.539890</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>300</td>\n",
       "      <td>3.753921</td>\n",
       "      <td>32.777654</td>\n",
       "      <td>3.753921</td>\n",
       "      <td>3.632639</td>\n",
       "      <td>31.353646</td>\n",
       "      <td>3.632639</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>500</td>\n",
       "      <td>3.755052</td>\n",
       "      <td>32.541730</td>\n",
       "      <td>3.755052</td>\n",
       "      <td>3.669314</td>\n",
       "      <td>32.871388</td>\n",
       "      <td>3.669314</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>300</td>\n",
       "      <td>3.755685</td>\n",
       "      <td>31.874146</td>\n",
       "      <td>3.755685</td>\n",
       "      <td>3.058191</td>\n",
       "      <td>26.297916</td>\n",
       "      <td>3.058191</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>500</td>\n",
       "      <td>3.755775</td>\n",
       "      <td>33.029015</td>\n",
       "      <td>3.755775</td>\n",
       "      <td>3.961876</td>\n",
       "      <td>36.317668</td>\n",
       "      <td>3.961876</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>300</td>\n",
       "      <td>3.757318</td>\n",
       "      <td>31.918555</td>\n",
       "      <td>3.757318</td>\n",
       "      <td>3.078010</td>\n",
       "      <td>26.106072</td>\n",
       "      <td>3.078010</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>300</td>\n",
       "      <td>3.765824</td>\n",
       "      <td>31.696141</td>\n",
       "      <td>3.765824</td>\n",
       "      <td>2.816351</td>\n",
       "      <td>24.662687</td>\n",
       "      <td>2.816351</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>300</td>\n",
       "      <td>3.770750</td>\n",
       "      <td>31.910518</td>\n",
       "      <td>3.770750</td>\n",
       "      <td>2.927274</td>\n",
       "      <td>25.975331</td>\n",
       "      <td>2.927274</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>500</td>\n",
       "      <td>3.772557</td>\n",
       "      <td>32.409633</td>\n",
       "      <td>3.772557</td>\n",
       "      <td>3.210413</td>\n",
       "      <td>26.573733</td>\n",
       "      <td>3.210413</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>500</td>\n",
       "      <td>3.773602</td>\n",
       "      <td>31.924805</td>\n",
       "      <td>3.773602</td>\n",
       "      <td>3.502557</td>\n",
       "      <td>31.548055</td>\n",
       "      <td>3.502557</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>500</td>\n",
       "      <td>3.775080</td>\n",
       "      <td>34.020546</td>\n",
       "      <td>3.775080</td>\n",
       "      <td>3.852751</td>\n",
       "      <td>34.390014</td>\n",
       "      <td>3.852751</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>500</td>\n",
       "      <td>3.776055</td>\n",
       "      <td>32.194542</td>\n",
       "      <td>3.776055</td>\n",
       "      <td>2.863006</td>\n",
       "      <td>25.495555</td>\n",
       "      <td>2.863006</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "68            500  3.726943               32.047591                 3.726943   \n",
       "45            500  3.729600               32.526435                 3.729600   \n",
       "32            500  3.736840               31.898237                 3.736840   \n",
       "142           500  3.746110               32.187851                 3.746110   \n",
       "90            300  3.748397               32.422323                 3.748397   \n",
       "77            300  3.750573               31.803752                 3.750573   \n",
       "41            300  3.752030               32.847059                 3.752030   \n",
       "91            300  3.753161               31.281720                 3.753161   \n",
       "116           500  3.753482               32.528194                 3.753482   \n",
       "28            300  3.753921               32.777654                 3.753921   \n",
       "80            500  3.755052               32.541730                 3.755052   \n",
       "127           300  3.755685               31.874146                 3.755685   \n",
       "93            500  3.755775               33.029015                 3.755775   \n",
       "29            300  3.757318               31.918555                 3.757318   \n",
       "17            300  3.765824               31.696141                 3.765824   \n",
       "65            300  3.770750               31.910518                 3.770750   \n",
       "94            500  3.772557               32.409633                 3.772557   \n",
       "129           500  3.773602               31.924805                 3.773602   \n",
       "44            500  3.775080               34.020546                 3.775080   \n",
       "56            500  3.776055               32.194542                 3.776055   \n",
       "\n",
       "         loss  mean_squared_error  mean_absolute_error activation  batch_size  \\\n",
       "68   3.415188           31.368683             3.415188       relu         128   \n",
       "45   3.613402           33.080520             3.613402       relu          64   \n",
       "32   3.079919           25.045749             3.079919       relu          64   \n",
       "142  3.481493           31.267456             3.481493       relu         256   \n",
       "90   3.680381           32.974671             3.680381       relu         128   \n",
       "77   3.473694           31.426172             3.473694       relu         128   \n",
       "41   3.706009           34.045101             3.706009       relu          64   \n",
       "91   3.212223           25.569225             3.212223       relu         128   \n",
       "116  3.539890           31.543397             3.539890       relu         256   \n",
       "28   3.632639           31.353646             3.632639       relu          64   \n",
       "80   3.669314           32.871388             3.669314       relu         128   \n",
       "127  3.058191           26.297916             3.058191       relu         256   \n",
       "93   3.961876           36.317668             3.961876       relu         128   \n",
       "29   3.078010           26.106072             3.078010       relu          64   \n",
       "17   2.816351           24.662687             2.816351       relu          64   \n",
       "65   2.927274           25.975331             2.927274       relu         128   \n",
       "94   3.210413           26.573733             3.210413       relu         128   \n",
       "129  3.502557           31.548055             3.502557       relu         256   \n",
       "44   3.852751           34.390014             3.852751       relu          64   \n",
       "56   2.863006           25.495555             2.863006       relu         128   \n",
       "\n",
       "     dropout  epochs  filters_first  kernel_size loss padding  \n",
       "68       0.2     500              4            3  mae    same  \n",
       "45       0.8     500              8            3  mae    same  \n",
       "32       0.5     500              4            3  mae    same  \n",
       "142      0.8     500             16            3  mae    same  \n",
       "90       0.8     300             16            3  mae    same  \n",
       "77       0.5     300              8            3  mae    same  \n",
       "41       0.8     300              8            3  mae    same  \n",
       "91       0.8     300             32            3  mae    same  \n",
       "116      0.2     500              4            3  mae    same  \n",
       "28       0.5     300              4            3  mae    same  \n",
       "80       0.5     500              4            3  mae    same  \n",
       "127      0.5     300             32            3  mae    same  \n",
       "93       0.8     500              8            3  mae    same  \n",
       "29       0.5     300              8            3  mae    same  \n",
       "17       0.2     300              8            3  mae    same  \n",
       "65       0.2     300              8            3  mae    same  \n",
       "94       0.8     500             16            3  mae    same  \n",
       "129      0.5     500              8            3  mae    same  \n",
       "44       0.8     500              4            3  mae    same  \n",
       "56       0.0     500              4            3  mae    same  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cnn1.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_2l_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    MAX_SEQUENCE_LENGTH = x_train.shape[1]\n",
    "    \n",
    "    global embedding_matrix\n",
    "    \n",
    "    embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                     output_dim=embedding_matrix.shape[1],\n",
    "                     mask_zero=False,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=MAX_SEQUENCE_LENGTH,\n",
    "                     trainable=False)\n",
    "\n",
    "    line_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name=\"input\")\n",
    "    embedded_sequences = embedding_layer(line_input)\n",
    "    cnn = Conv1D(filters=params['filters_first'], kernel_size=params['kernel_size'], strides=1, \n",
    "                        padding=params['padding'],\n",
    "                        activation=params['activation'])(embedded_sequences)\n",
    "    cnn = AveragePooling1D(pool_size=2)(cnn)\n",
    "    cnn = Conv1D(filters=params['filters_second'], kernel_size=params['kernel_size'], strides=1, \n",
    "                        padding=params['padding'],\n",
    "                        activation=params['activation'])(cnn)\n",
    "    cnn = AveragePooling1D(pool_size=2)(cnn)\n",
    "\n",
    "    cnn = Flatten()(cnn)\n",
    "\n",
    "    cnn = Dropout(params['dropout'])(cnn)\n",
    "\n",
    "    output = Dense(1, activation='linear')(cnn)\n",
    "\n",
    "    model = Model([line_input] , output) \n",
    "    \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.95, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=params['loss'],\n",
    "                  metrics=['mse', 'mae'])\n",
    "\n",
    "    callbacks_list = [\n",
    "        ReduceLROnPlateau( \n",
    "            monitor='loss',\n",
    "            min_lr=0.001,\n",
    "            factor=0.5,\n",
    "            verbose=1,\n",
    "            patience=10), \n",
    "    ]\n",
    "    \n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[x_val, y_val])\n",
    "    return out, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters_first':[4, 8, 16, 32],\n",
    "     'filters_second':[4, 8, 16, 32],\n",
    "     'kernel_size':[3],\n",
    "     'batch_size': [64, 128, 256],\n",
    "     'epochs': [100, 300, 500],\n",
    "     'dropout': [0, 0.2, 0.5, 0.8],\n",
    "     'padding' : ['same',],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 576/576 [1:16:39<00:00,  8.16s/it]\n"
     ]
    }
   ],
   "source": [
    "h_cnn2 = ta.Scan(x, y, params=p,\n",
    "            model=get_cnn_2l_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2 = ta.Reporting(h_cnn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}cnn2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters_first</th>\n",
       "      <th>filters_second</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>padding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>300</td>\n",
       "      <td>3.681885</td>\n",
       "      <td>32.034462</td>\n",
       "      <td>3.681885</td>\n",
       "      <td>3.573565</td>\n",
       "      <td>31.586531</td>\n",
       "      <td>3.573565</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>100</td>\n",
       "      <td>3.699152</td>\n",
       "      <td>32.437884</td>\n",
       "      <td>3.699152</td>\n",
       "      <td>3.404536</td>\n",
       "      <td>32.041352</td>\n",
       "      <td>3.404536</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>100</td>\n",
       "      <td>3.703135</td>\n",
       "      <td>32.599696</td>\n",
       "      <td>3.703135</td>\n",
       "      <td>3.618919</td>\n",
       "      <td>30.540457</td>\n",
       "      <td>3.618919</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>300</td>\n",
       "      <td>3.711105</td>\n",
       "      <td>33.078178</td>\n",
       "      <td>3.711105</td>\n",
       "      <td>3.483870</td>\n",
       "      <td>29.878112</td>\n",
       "      <td>3.483870</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>100</td>\n",
       "      <td>3.716900</td>\n",
       "      <td>32.692255</td>\n",
       "      <td>3.716900</td>\n",
       "      <td>3.655466</td>\n",
       "      <td>30.587623</td>\n",
       "      <td>3.655466</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>300</td>\n",
       "      <td>3.717098</td>\n",
       "      <td>32.182449</td>\n",
       "      <td>3.717098</td>\n",
       "      <td>3.099026</td>\n",
       "      <td>27.892264</td>\n",
       "      <td>3.099026</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>300</td>\n",
       "      <td>3.722425</td>\n",
       "      <td>31.837513</td>\n",
       "      <td>3.722425</td>\n",
       "      <td>3.640665</td>\n",
       "      <td>34.000961</td>\n",
       "      <td>3.640665</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>300</td>\n",
       "      <td>3.724686</td>\n",
       "      <td>33.788252</td>\n",
       "      <td>3.724686</td>\n",
       "      <td>3.821708</td>\n",
       "      <td>34.492095</td>\n",
       "      <td>3.821708</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>300</td>\n",
       "      <td>3.724966</td>\n",
       "      <td>33.057690</td>\n",
       "      <td>3.724966</td>\n",
       "      <td>3.735871</td>\n",
       "      <td>34.255339</td>\n",
       "      <td>3.735871</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>100</td>\n",
       "      <td>3.725416</td>\n",
       "      <td>32.329051</td>\n",
       "      <td>3.725416</td>\n",
       "      <td>3.313602</td>\n",
       "      <td>29.188136</td>\n",
       "      <td>3.313602</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>300</td>\n",
       "      <td>3.726120</td>\n",
       "      <td>32.827110</td>\n",
       "      <td>3.726120</td>\n",
       "      <td>3.818012</td>\n",
       "      <td>34.120090</td>\n",
       "      <td>3.818012</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>3.731236</td>\n",
       "      <td>31.976007</td>\n",
       "      <td>3.731236</td>\n",
       "      <td>3.463837</td>\n",
       "      <td>29.900595</td>\n",
       "      <td>3.463837</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>300</td>\n",
       "      <td>3.731275</td>\n",
       "      <td>33.551018</td>\n",
       "      <td>3.731275</td>\n",
       "      <td>3.585635</td>\n",
       "      <td>31.797745</td>\n",
       "      <td>3.585635</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>100</td>\n",
       "      <td>3.732751</td>\n",
       "      <td>33.019889</td>\n",
       "      <td>3.732751</td>\n",
       "      <td>3.155272</td>\n",
       "      <td>28.379673</td>\n",
       "      <td>3.155272</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>300</td>\n",
       "      <td>3.733040</td>\n",
       "      <td>32.401234</td>\n",
       "      <td>3.733040</td>\n",
       "      <td>3.312808</td>\n",
       "      <td>28.187967</td>\n",
       "      <td>3.312808</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>300</td>\n",
       "      <td>3.735540</td>\n",
       "      <td>33.965546</td>\n",
       "      <td>3.735540</td>\n",
       "      <td>4.161641</td>\n",
       "      <td>39.638438</td>\n",
       "      <td>4.161641</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>300</td>\n",
       "      <td>3.735549</td>\n",
       "      <td>32.734142</td>\n",
       "      <td>3.735549</td>\n",
       "      <td>3.050258</td>\n",
       "      <td>27.457797</td>\n",
       "      <td>3.050258</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>100</td>\n",
       "      <td>3.741591</td>\n",
       "      <td>33.119616</td>\n",
       "      <td>3.741591</td>\n",
       "      <td>3.612671</td>\n",
       "      <td>30.602285</td>\n",
       "      <td>3.612671</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>100</td>\n",
       "      <td>3.742183</td>\n",
       "      <td>32.194104</td>\n",
       "      <td>3.742183</td>\n",
       "      <td>3.510240</td>\n",
       "      <td>30.265559</td>\n",
       "      <td>3.510240</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>500</td>\n",
       "      <td>3.742900</td>\n",
       "      <td>33.836987</td>\n",
       "      <td>3.742900</td>\n",
       "      <td>3.687428</td>\n",
       "      <td>32.513370</td>\n",
       "      <td>3.687428</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "498           300  3.681885               32.034462                 3.681885   \n",
       "103           100  3.699152               32.437884                 3.699152   \n",
       "109           100  3.703135               32.599696                 3.703135   \n",
       "501           300  3.711105               33.078178                 3.711105   \n",
       "155           100  3.716900               32.692255                 3.716900   \n",
       "400           300  3.717098               32.182449                 3.717098   \n",
       "502           300  3.722425               31.837513                 3.722425   \n",
       "308           300  3.724686               33.788252                 3.724686   \n",
       "550           300  3.724966               33.057690                 3.724966   \n",
       "253           100  3.725416               32.329051                 3.725416   \n",
       "547           300  3.726120               32.827110                 3.726120   \n",
       "99            100  3.731236               31.976007                 3.731236   \n",
       "551           300  3.731275               33.551018                 3.731275   \n",
       "203           100  3.732751               33.019889                 3.732751   \n",
       "452           300  3.733040               32.401234                 3.733040   \n",
       "554           300  3.735540               33.965546                 3.735540   \n",
       "402           300  3.735549               32.734142                 3.735549   \n",
       "106           100  3.741591               33.119616                 3.741591   \n",
       "151           100  3.742183               32.194104                 3.742183   \n",
       "512           500  3.742900               33.836987                 3.742900   \n",
       "\n",
       "         loss  mean_squared_error  mean_absolute_error activation  batch_size  \\\n",
       "498  3.573565           31.586531             3.573565       relu         256   \n",
       "103  3.404536           32.041352             3.404536       relu          64   \n",
       "109  3.618919           30.540457             3.618919       relu          64   \n",
       "501  3.483870           29.878112             3.483870       relu         256   \n",
       "155  3.655466           30.587623             3.655466       relu          64   \n",
       "400  3.099026           27.892264             3.099026       relu         256   \n",
       "502  3.640665           34.000961             3.640665       relu         256   \n",
       "308  3.821708           34.492095             3.821708       relu         128   \n",
       "550  3.735871           34.255339             3.735871       relu         256   \n",
       "253  3.313602           29.188136             3.313602       relu         128   \n",
       "547  3.818012           34.120090             3.818012       relu         256   \n",
       "99   3.463837           29.900595             3.463837       relu          64   \n",
       "551  3.585635           31.797745             3.585635       relu         256   \n",
       "203  3.155272           28.379673             3.155272       relu         128   \n",
       "452  3.312808           28.187967             3.312808       relu         256   \n",
       "554  4.161641           39.638438             4.161641       relu         256   \n",
       "402  3.050258           27.457797             3.050258       relu         256   \n",
       "106  3.612671           30.602285             3.612671       relu          64   \n",
       "151  3.510240           30.265559             3.510240       relu          64   \n",
       "512  3.687428           32.513370             3.687428       relu         256   \n",
       "\n",
       "     dropout  epochs  filters_first  filters_second  kernel_size loss padding  \n",
       "498      0.5     300              4              16            3  mae    same  \n",
       "103      0.5     100              8              32            3  mae    same  \n",
       "109      0.5     100             32               8            3  mae    same  \n",
       "501      0.5     300              8               8            3  mae    same  \n",
       "155      0.8     100             16              32            3  mae    same  \n",
       "400      0.0     300              4               4            3  mae    same  \n",
       "502      0.5     300              8              16            3  mae    same  \n",
       "308      0.5     300              8               4            3  mae    same  \n",
       "550      0.8     300              8              16            3  mae    same  \n",
       "253      0.2     100             32               8            3  mae    same  \n",
       "547      0.8     300              4              32            3  mae    same  \n",
       "99       0.5     100              4              32            3  mae    same  \n",
       "551      0.8     300              8              32            3  mae    same  \n",
       "203      0.0     100             16              32            3  mae    same  \n",
       "452      0.2     300              8               4            3  mae    same  \n",
       "554      0.8     300             16              16            3  mae    same  \n",
       "402      0.0     300              4              16            3  mae    same  \n",
       "106      0.5     100             16              16            3  mae    same  \n",
       "151      0.8     100              8              32            3  mae    same  \n",
       "512      0.5     500              4               4            3  mae    same  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cnn2.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn_1l_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    MAX_SEQUENCE_LENGTH = x_train.shape[1]\n",
    "    \n",
    "    global embedding_matrix\n",
    "    \n",
    "    embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                     output_dim=embedding_matrix.shape[1],\n",
    "                     mask_zero=False,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=MAX_SEQUENCE_LENGTH,\n",
    "                     trainable=False)\n",
    "\n",
    "    line_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name=\"input\")\n",
    "    embedded_sequences = embedding_layer(line_input)\n",
    "    rnn = CuDNNGRU(params['units_first'], return_sequences=False,  stateful=False)(embedded_sequences)\n",
    "\n",
    "    rnn = Dropout(params['dropout'])(rnn)\n",
    "\n",
    "    output = Dense(1, activation='linear')(rnn)\n",
    "\n",
    "    model = Model([line_input] , output) \n",
    "    \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.95, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=params['loss'],\n",
    "                  metrics=['mse', 'mae'])\n",
    "\n",
    "    callbacks_list = [\n",
    "        ReduceLROnPlateau( \n",
    "            monitor='loss',\n",
    "            min_lr=0.001,\n",
    "            factor=0.5,\n",
    "            verbose=1,\n",
    "            patience=10), \n",
    "    ]\n",
    "    \n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[x_val, y_val])\n",
    "    return out, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'units_first':[4, 8, 16, 32],\n",
    "     'batch_size': [64, 128, 256],\n",
    "     'epochs': [100, 300, 500],\n",
    "     'dropout': [0, 0.2, 0.5, 0.8],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 144/144 [25:18<00:00,  8.70s/it]\n"
     ]
    }
   ],
   "source": [
    "h_rnn1 = ta.Scan(x, y, params=p,\n",
    "            model=get_rnn_1l_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_rnn1 = ta.Reporting(h_rnn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_rnn1.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}rnn1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>units_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100</td>\n",
       "      <td>4.017101</td>\n",
       "      <td>34.435091</td>\n",
       "      <td>4.017101</td>\n",
       "      <td>3.807407</td>\n",
       "      <td>34.757183</td>\n",
       "      <td>3.807407</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>300</td>\n",
       "      <td>4.055992</td>\n",
       "      <td>36.333089</td>\n",
       "      <td>4.055992</td>\n",
       "      <td>3.591587</td>\n",
       "      <td>35.107207</td>\n",
       "      <td>3.591587</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>300</td>\n",
       "      <td>4.081528</td>\n",
       "      <td>34.772911</td>\n",
       "      <td>4.081528</td>\n",
       "      <td>2.889139</td>\n",
       "      <td>26.886685</td>\n",
       "      <td>2.889139</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>500</td>\n",
       "      <td>4.095769</td>\n",
       "      <td>36.172653</td>\n",
       "      <td>4.095769</td>\n",
       "      <td>1.869107</td>\n",
       "      <td>16.747403</td>\n",
       "      <td>1.869107</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>500</td>\n",
       "      <td>4.095810</td>\n",
       "      <td>35.786087</td>\n",
       "      <td>4.095810</td>\n",
       "      <td>3.194524</td>\n",
       "      <td>26.151485</td>\n",
       "      <td>3.194524</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>300</td>\n",
       "      <td>4.105294</td>\n",
       "      <td>34.543590</td>\n",
       "      <td>4.105294</td>\n",
       "      <td>2.710173</td>\n",
       "      <td>22.326963</td>\n",
       "      <td>2.710173</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300</td>\n",
       "      <td>4.140781</td>\n",
       "      <td>42.310783</td>\n",
       "      <td>4.140781</td>\n",
       "      <td>3.865497</td>\n",
       "      <td>41.375933</td>\n",
       "      <td>3.865497</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>300</td>\n",
       "      <td>4.150539</td>\n",
       "      <td>38.537380</td>\n",
       "      <td>4.150539</td>\n",
       "      <td>4.125519</td>\n",
       "      <td>39.989468</td>\n",
       "      <td>4.125519</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>4.155402</td>\n",
       "      <td>35.595623</td>\n",
       "      <td>4.155402</td>\n",
       "      <td>3.674241</td>\n",
       "      <td>34.038256</td>\n",
       "      <td>3.674241</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>300</td>\n",
       "      <td>4.161576</td>\n",
       "      <td>35.398808</td>\n",
       "      <td>4.161576</td>\n",
       "      <td>2.095459</td>\n",
       "      <td>18.812130</td>\n",
       "      <td>2.095459</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>500</td>\n",
       "      <td>4.178076</td>\n",
       "      <td>40.671730</td>\n",
       "      <td>4.178076</td>\n",
       "      <td>3.758275</td>\n",
       "      <td>36.027516</td>\n",
       "      <td>3.758275</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>300</td>\n",
       "      <td>4.180052</td>\n",
       "      <td>35.932521</td>\n",
       "      <td>4.180052</td>\n",
       "      <td>1.257105</td>\n",
       "      <td>10.939476</td>\n",
       "      <td>1.257105</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>500</td>\n",
       "      <td>4.181136</td>\n",
       "      <td>35.397621</td>\n",
       "      <td>4.181136</td>\n",
       "      <td>2.596993</td>\n",
       "      <td>20.695753</td>\n",
       "      <td>2.596993</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>300</td>\n",
       "      <td>4.185814</td>\n",
       "      <td>38.834160</td>\n",
       "      <td>4.185814</td>\n",
       "      <td>3.983208</td>\n",
       "      <td>38.231281</td>\n",
       "      <td>3.983208</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>300</td>\n",
       "      <td>4.193403</td>\n",
       "      <td>34.962024</td>\n",
       "      <td>4.193403</td>\n",
       "      <td>2.687731</td>\n",
       "      <td>23.531743</td>\n",
       "      <td>2.687731</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>300</td>\n",
       "      <td>4.195341</td>\n",
       "      <td>39.296369</td>\n",
       "      <td>4.195341</td>\n",
       "      <td>3.272593</td>\n",
       "      <td>29.646784</td>\n",
       "      <td>3.272593</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>300</td>\n",
       "      <td>4.196837</td>\n",
       "      <td>38.787998</td>\n",
       "      <td>4.196837</td>\n",
       "      <td>4.299583</td>\n",
       "      <td>40.100926</td>\n",
       "      <td>4.299583</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>300</td>\n",
       "      <td>4.199859</td>\n",
       "      <td>42.888015</td>\n",
       "      <td>4.199859</td>\n",
       "      <td>4.531012</td>\n",
       "      <td>49.851030</td>\n",
       "      <td>4.531012</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>300</td>\n",
       "      <td>4.207895</td>\n",
       "      <td>36.962851</td>\n",
       "      <td>4.207895</td>\n",
       "      <td>3.247727</td>\n",
       "      <td>31.421289</td>\n",
       "      <td>3.247727</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>300</td>\n",
       "      <td>4.212234</td>\n",
       "      <td>39.833717</td>\n",
       "      <td>4.212234</td>\n",
       "      <td>3.645862</td>\n",
       "      <td>36.415019</td>\n",
       "      <td>3.645862</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "27            100  4.017101               34.435091                 4.017101   \n",
       "91            300  4.055992               36.333089                 4.055992   \n",
       "103           300  4.081528               34.772911                 4.081528   \n",
       "107           500  4.095769               36.172653                 4.095769   \n",
       "143           500  4.095810               35.786087                 4.095810   \n",
       "79            300  4.105294               34.543590                 4.105294   \n",
       "4             300  4.140781               42.310783                 4.140781   \n",
       "127           300  4.150539               38.537380                 4.150539   \n",
       "15            100  4.155402               35.595623                 4.155402   \n",
       "55            300  4.161576               35.398808                 4.161576   \n",
       "94            500  4.178076               40.671730                 4.178076   \n",
       "7             300  4.180052               35.932521                 4.180052   \n",
       "131           500  4.181136               35.397621                 4.181136   \n",
       "139           300  4.185814               38.834160                 4.185814   \n",
       "67            300  4.193403               34.962024                 4.193403   \n",
       "78            300  4.195341               39.296369                 4.195341   \n",
       "90            300  4.196837               38.787998                 4.196837   \n",
       "77            300  4.199859               42.888015                 4.199859   \n",
       "54            300  4.207895               36.962851                 4.207895   \n",
       "65            300  4.212234               39.833717                 4.212234   \n",
       "\n",
       "         loss  mean_squared_error  mean_absolute_error activation  batch_size  \\\n",
       "27   3.807407           34.757183             3.807407       relu          64   \n",
       "91   3.591587           35.107207             3.591587       relu         128   \n",
       "103  2.889139           26.886685             2.889139       relu         256   \n",
       "107  1.869107           16.747403             1.869107       relu         256   \n",
       "143  3.194524           26.151485             3.194524       relu         256   \n",
       "79   2.710173           22.326963             2.710173       relu         128   \n",
       "4    3.865497           41.375933             3.865497       relu          64   \n",
       "127  4.125519           39.989468             4.125519       relu         256   \n",
       "15   3.674241           34.038256             3.674241       relu          64   \n",
       "55   2.095459           18.812130             2.095459       relu         128   \n",
       "94   3.758275           36.027516             3.758275       relu         128   \n",
       "7    1.257105           10.939476             1.257105       relu          64   \n",
       "131  2.596993           20.695753             2.596993       relu         256   \n",
       "139  3.983208           38.231281             3.983208       relu         256   \n",
       "67   2.687731           23.531743             2.687731       relu         128   \n",
       "78   3.272593           29.646784             3.272593       relu         128   \n",
       "90   4.299583           40.100926             4.299583       relu         128   \n",
       "77   4.531012           49.851030             4.531012       relu         128   \n",
       "54   3.247727           31.421289             3.247727       relu         128   \n",
       "65   3.645862           36.415019             3.645862       relu         128   \n",
       "\n",
       "     dropout  epochs loss  units_first  \n",
       "27       0.5     100  mae           32  \n",
       "91       0.8     300  mae           32  \n",
       "103      0.0     300  mae           32  \n",
       "107      0.0     500  mae           32  \n",
       "143      0.8     500  mae           32  \n",
       "79       0.5     300  mae           32  \n",
       "4        0.0     300  mae            4  \n",
       "127      0.5     300  mae           32  \n",
       "15       0.2     100  mae           32  \n",
       "55       0.0     300  mae           32  \n",
       "94       0.8     500  mae           16  \n",
       "7        0.0     300  mae           32  \n",
       "131      0.5     500  mae           32  \n",
       "139      0.8     300  mae           32  \n",
       "67       0.2     300  mae           32  \n",
       "78       0.5     300  mae           16  \n",
       "90       0.8     300  mae           16  \n",
       "77       0.5     300  mae            8  \n",
       "54       0.0     300  mae           16  \n",
       "65       0.2     300  mae            8  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_rnn1.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn_2l_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    MAX_SEQUENCE_LENGTH = x_train.shape[1]\n",
    "    \n",
    "    global embedding_matrix\n",
    "    \n",
    "    embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                     output_dim=embedding_matrix.shape[1],\n",
    "                     mask_zero=False,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=MAX_SEQUENCE_LENGTH,\n",
    "                     trainable=False)\n",
    "\n",
    "    line_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name=\"input\")\n",
    "    embedded_sequences = embedding_layer(line_input)\n",
    "    rnn = CuDNNGRU(params['units_first'], return_sequences=True,  stateful=False)(embedded_sequences)\n",
    "    rnn = CuDNNGRU(params['units_second'], return_sequences=False,  stateful=False)(rnn)\n",
    "\n",
    "    rnn = Dropout(params['dropout'])(rnn)\n",
    "\n",
    "    output = Dense(1, activation='linear')(rnn)\n",
    "\n",
    "    model = Model([line_input] , output) \n",
    "    \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.95, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=params['loss'],\n",
    "                  metrics=['mse', 'mae'])\n",
    "\n",
    "    callbacks_list = [\n",
    "        ReduceLROnPlateau( \n",
    "            monitor='loss',\n",
    "            min_lr=0.001,\n",
    "            factor=0.5,\n",
    "            verbose=1,\n",
    "            patience=10), \n",
    "    ]\n",
    "    \n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[x_val, y_val])\n",
    "    return out, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'units_first':[4, 8, 16, 32],\n",
    "     'units_second':[4, 8, 16, 32],\n",
    "     'batch_size': [64, 128, 256],\n",
    "     'epochs': [100, 300, 500],\n",
    "     'dropout': [0, 0.2, 0.5, 0.8],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 576/576 [2:34:29<00:00, 17.03s/it]\n"
     ]
    }
   ],
   "source": [
    "h_rnn2 = ta.Scan(x, y, params=p,\n",
    "            model=get_rnn_2l_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_rnn2 = ta.Reporting(h_rnn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_rnn2.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}rnn2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>loss</th>\n",
       "      <th>units_first</th>\n",
       "      <th>units_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>300</td>\n",
       "      <td>3.937490</td>\n",
       "      <td>34.544248</td>\n",
       "      <td>3.937490</td>\n",
       "      <td>2.591791</td>\n",
       "      <td>20.360330</td>\n",
       "      <td>2.591791</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>500</td>\n",
       "      <td>3.940184</td>\n",
       "      <td>34.611366</td>\n",
       "      <td>3.940184</td>\n",
       "      <td>2.575337</td>\n",
       "      <td>20.541347</td>\n",
       "      <td>2.575337</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>500</td>\n",
       "      <td>3.985820</td>\n",
       "      <td>35.956879</td>\n",
       "      <td>3.985820</td>\n",
       "      <td>2.160543</td>\n",
       "      <td>16.590963</td>\n",
       "      <td>2.160543</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>300</td>\n",
       "      <td>3.993645</td>\n",
       "      <td>35.797341</td>\n",
       "      <td>3.993645</td>\n",
       "      <td>1.932441</td>\n",
       "      <td>16.772294</td>\n",
       "      <td>1.932441</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>300</td>\n",
       "      <td>4.005436</td>\n",
       "      <td>34.789242</td>\n",
       "      <td>4.005436</td>\n",
       "      <td>2.672401</td>\n",
       "      <td>23.130051</td>\n",
       "      <td>2.672401</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>300</td>\n",
       "      <td>4.008783</td>\n",
       "      <td>34.232544</td>\n",
       "      <td>4.008783</td>\n",
       "      <td>2.392893</td>\n",
       "      <td>20.078534</td>\n",
       "      <td>2.392893</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>4.024505</td>\n",
       "      <td>34.176532</td>\n",
       "      <td>4.024505</td>\n",
       "      <td>2.661223</td>\n",
       "      <td>23.353004</td>\n",
       "      <td>2.661223</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>mae</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>500</td>\n",
       "      <td>4.024805</td>\n",
       "      <td>35.468475</td>\n",
       "      <td>4.024805</td>\n",
       "      <td>3.155714</td>\n",
       "      <td>25.000165</td>\n",
       "      <td>3.155714</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>300</td>\n",
       "      <td>4.026302</td>\n",
       "      <td>35.304062</td>\n",
       "      <td>4.026302</td>\n",
       "      <td>2.290792</td>\n",
       "      <td>20.456797</td>\n",
       "      <td>2.290792</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>500</td>\n",
       "      <td>4.028748</td>\n",
       "      <td>35.833904</td>\n",
       "      <td>4.028748</td>\n",
       "      <td>2.842785</td>\n",
       "      <td>24.800153</td>\n",
       "      <td>2.842785</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>500</td>\n",
       "      <td>4.030504</td>\n",
       "      <td>35.146572</td>\n",
       "      <td>4.030504</td>\n",
       "      <td>2.464397</td>\n",
       "      <td>21.658545</td>\n",
       "      <td>2.464397</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>500</td>\n",
       "      <td>4.031528</td>\n",
       "      <td>35.997265</td>\n",
       "      <td>4.031528</td>\n",
       "      <td>2.190375</td>\n",
       "      <td>16.778145</td>\n",
       "      <td>2.190375</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>500</td>\n",
       "      <td>4.040289</td>\n",
       "      <td>36.414073</td>\n",
       "      <td>4.040289</td>\n",
       "      <td>2.902739</td>\n",
       "      <td>22.213557</td>\n",
       "      <td>2.902739</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>300</td>\n",
       "      <td>4.049809</td>\n",
       "      <td>35.088903</td>\n",
       "      <td>4.049809</td>\n",
       "      <td>2.336860</td>\n",
       "      <td>19.519478</td>\n",
       "      <td>2.336860</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>300</td>\n",
       "      <td>4.050625</td>\n",
       "      <td>34.932556</td>\n",
       "      <td>4.050625</td>\n",
       "      <td>3.369647</td>\n",
       "      <td>32.418222</td>\n",
       "      <td>3.369647</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>300</td>\n",
       "      <td>4.050711</td>\n",
       "      <td>34.750697</td>\n",
       "      <td>4.050711</td>\n",
       "      <td>2.173753</td>\n",
       "      <td>19.819827</td>\n",
       "      <td>2.173753</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>mae</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>500</td>\n",
       "      <td>4.054302</td>\n",
       "      <td>35.969281</td>\n",
       "      <td>4.054302</td>\n",
       "      <td>2.444296</td>\n",
       "      <td>18.466745</td>\n",
       "      <td>2.444296</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>4.054308</td>\n",
       "      <td>34.703605</td>\n",
       "      <td>4.054308</td>\n",
       "      <td>3.079366</td>\n",
       "      <td>29.508735</td>\n",
       "      <td>3.079366</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>500</td>\n",
       "      <td>4.058937</td>\n",
       "      <td>35.541176</td>\n",
       "      <td>4.058937</td>\n",
       "      <td>3.448320</td>\n",
       "      <td>30.859447</td>\n",
       "      <td>3.448320</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>500</td>\n",
       "      <td>4.059365</td>\n",
       "      <td>36.145811</td>\n",
       "      <td>4.059365</td>\n",
       "      <td>2.730947</td>\n",
       "      <td>22.350007</td>\n",
       "      <td>2.730947</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>mae</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "315           300  3.937490               34.544248                 3.937490   \n",
       "467           500  3.940184               34.611366                 3.940184   \n",
       "82            500  3.985820               35.956879                 3.985820   \n",
       "22            300  3.993645               35.797341                 3.993645   \n",
       "459           300  4.005436               34.789242                 4.005436   \n",
       "411           300  4.008783               34.232544                 4.008783   \n",
       "11            100  4.024505               34.176532                 4.024505   \n",
       "571           500  4.024805               35.468475                 4.024805   \n",
       "18            300  4.026302               35.304062                 4.026302   \n",
       "519           500  4.028748               35.833904                 4.028748   \n",
       "419           500  4.030504               35.146572                 4.030504   \n",
       "471           500  4.031528               35.997265                 4.031528   \n",
       "379           500  4.040289               36.414073                 4.040289   \n",
       "70            300  4.049809               35.088903                 4.049809   \n",
       "415           300  4.050625               34.932556                 4.050625   \n",
       "214           300  4.050711               34.750697                 4.050711   \n",
       "323           500  4.054302               35.969281                 4.054302   \n",
       "15            100  4.054308               34.703605                 4.054308   \n",
       "567           500  4.058937               35.541176                 4.058937   \n",
       "142           500  4.059365               36.145811                 4.059365   \n",
       "\n",
       "         loss  mean_squared_error  mean_absolute_error activation  batch_size  \\\n",
       "315  2.591791           20.360330             2.591791       relu         128   \n",
       "467  2.575337           20.541347             2.575337       relu         256   \n",
       "82   2.160543           16.590963             2.160543       relu          64   \n",
       "22   1.932441           16.772294             1.932441       relu          64   \n",
       "459  2.672401           23.130051             2.672401       relu         256   \n",
       "411  2.392893           20.078534             2.392893       relu         256   \n",
       "11   2.661223           23.353004             2.661223       relu          64   \n",
       "571  3.155714           25.000165             3.155714       relu         256   \n",
       "18   2.290792           20.456797             2.290792       relu          64   \n",
       "519  2.842785           24.800153             2.842785       relu         256   \n",
       "419  2.464397           21.658545             2.464397       relu         256   \n",
       "471  2.190375           16.778145             2.190375       relu         256   \n",
       "379  2.902739           22.213557             2.902739       relu         128   \n",
       "70   2.336860           19.519478             2.336860       relu          64   \n",
       "415  3.369647           32.418222             3.369647       relu         256   \n",
       "214  2.173753           19.819827             2.173753       relu         128   \n",
       "323  2.444296           18.466745             2.444296       relu         128   \n",
       "15   3.079366           29.508735             3.079366       relu          64   \n",
       "567  3.448320           30.859447             3.448320       relu         256   \n",
       "142  2.730947           22.350007             2.730947       relu          64   \n",
       "\n",
       "     dropout  epochs loss  units_first  units_second  \n",
       "315      0.5     300  mae           16            32  \n",
       "467      0.2     500  mae            4            32  \n",
       "82       0.2     500  mae            4            16  \n",
       "22       0.0     300  mae            8            16  \n",
       "459      0.2     300  mae           16            32  \n",
       "411      0.0     300  mae           16            32  \n",
       "11       0.0     100  mae           16            32  \n",
       "571      0.8     500  mae           16            32  \n",
       "18       0.0     300  mae            4            16  \n",
       "519      0.5     500  mae            8            32  \n",
       "419      0.0     500  mae            4            32  \n",
       "471      0.2     500  mae            8            32  \n",
       "379      0.8     500  mae           16            32  \n",
       "70       0.2     300  mae            8            16  \n",
       "415      0.0     300  mae           32            32  \n",
       "214      0.0     300  mae            8            16  \n",
       "323      0.5     500  mae            4            32  \n",
       "15       0.0     100  mae           32            32  \n",
       "567      0.8     500  mae            8            32  \n",
       "142      0.5     500  mae           32            16  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_rnn2.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_rnn_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    MAX_SEQUENCE_LENGTH = x_train.shape[1]\n",
    "    \n",
    "    global embedding_matrix\n",
    "    \n",
    "    embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                     output_dim=embedding_matrix.shape[1],\n",
    "                     mask_zero=False,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=MAX_SEQUENCE_LENGTH,\n",
    "                     trainable=False)\n",
    "\n",
    "    line_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name=\"input\")\n",
    "    embedded_sequences = embedding_layer(line_input)\n",
    "    \n",
    "    cnn = Conv1D(filters=params['filters_first'], kernel_size=params['kernel_size'], strides=1, \n",
    "                        padding=params['padding'],\n",
    "                        activation=params['activation'])(embedded_sequences)\n",
    "    cnn = AveragePooling1D(pool_size=2)(cnn)\n",
    "    \n",
    "    rnn = CuDNNGRU(params['units_first'], return_sequences=False,  stateful=False)(cnn)\n",
    "\n",
    "    rnn = Dropout(params['dropout'])(rnn)\n",
    "\n",
    "    output = Dense(1, activation='linear')(rnn)\n",
    "\n",
    "    model = Model([line_input] , output) \n",
    "    \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.95, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=params['loss'],\n",
    "                  metrics=['mse', 'mae'])\n",
    "\n",
    "    callbacks_list = [\n",
    "        ReduceLROnPlateau( \n",
    "            monitor='loss',\n",
    "            min_lr=0.001,\n",
    "            factor=0.5,\n",
    "            verbose=1,\n",
    "            patience=10), \n",
    "    ]\n",
    "    \n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[x_val, y_val])\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters_first':[4, 8, 16, 32],\n",
    "     'units_first':[4, 8, 16, 32],\n",
    "     'kernel_size':[3],\n",
    "     'batch_size': [64, 128, 256],\n",
    "     'epochs': [100, 300, 500],\n",
    "     'dropout': [0, 0.2, 0.5, 0.8],\n",
    "     'padding' : ['same',],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 576/576 [1:49:53<00:00, 10.67s/it]\n"
     ]
    }
   ],
   "source": [
    "h_cnn_rnn = ta.Scan(x, y, params=p,\n",
    "            model=get_cnn_rnn_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn_rnn = ta.Reporting(h_cnn_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn_rnn.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}cnn_rnn.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters_first</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>padding</th>\n",
       "      <th>units_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>3.931706</td>\n",
       "      <td>33.633681</td>\n",
       "      <td>3.931706</td>\n",
       "      <td>2.357946</td>\n",
       "      <td>22.745678</td>\n",
       "      <td>2.357946</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>300</td>\n",
       "      <td>3.954406</td>\n",
       "      <td>34.150841</td>\n",
       "      <td>3.954406</td>\n",
       "      <td>2.471902</td>\n",
       "      <td>22.945651</td>\n",
       "      <td>2.471902</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>300</td>\n",
       "      <td>3.977251</td>\n",
       "      <td>33.501972</td>\n",
       "      <td>3.977251</td>\n",
       "      <td>2.466416</td>\n",
       "      <td>22.071932</td>\n",
       "      <td>2.466416</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>300</td>\n",
       "      <td>4.026696</td>\n",
       "      <td>34.355962</td>\n",
       "      <td>4.026696</td>\n",
       "      <td>2.500297</td>\n",
       "      <td>23.679653</td>\n",
       "      <td>2.500297</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>4.030043</td>\n",
       "      <td>34.276624</td>\n",
       "      <td>4.030043</td>\n",
       "      <td>2.950520</td>\n",
       "      <td>27.676142</td>\n",
       "      <td>2.950520</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>100</td>\n",
       "      <td>4.037873</td>\n",
       "      <td>35.138120</td>\n",
       "      <td>4.037873</td>\n",
       "      <td>3.407935</td>\n",
       "      <td>32.280970</td>\n",
       "      <td>3.407935</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>4.049980</td>\n",
       "      <td>36.534445</td>\n",
       "      <td>4.049980</td>\n",
       "      <td>3.625712</td>\n",
       "      <td>35.389202</td>\n",
       "      <td>3.625712</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>500</td>\n",
       "      <td>4.051798</td>\n",
       "      <td>35.326527</td>\n",
       "      <td>4.051798</td>\n",
       "      <td>2.495266</td>\n",
       "      <td>23.992723</td>\n",
       "      <td>2.495266</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>500</td>\n",
       "      <td>4.056374</td>\n",
       "      <td>34.480427</td>\n",
       "      <td>4.056374</td>\n",
       "      <td>3.054852</td>\n",
       "      <td>27.582959</td>\n",
       "      <td>3.054852</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>500</td>\n",
       "      <td>4.056850</td>\n",
       "      <td>35.321587</td>\n",
       "      <td>4.056850</td>\n",
       "      <td>2.040443</td>\n",
       "      <td>19.908373</td>\n",
       "      <td>2.040443</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>300</td>\n",
       "      <td>4.057975</td>\n",
       "      <td>34.304695</td>\n",
       "      <td>4.057975</td>\n",
       "      <td>2.049821</td>\n",
       "      <td>19.318914</td>\n",
       "      <td>2.049821</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>500</td>\n",
       "      <td>4.063852</td>\n",
       "      <td>34.379696</td>\n",
       "      <td>4.063852</td>\n",
       "      <td>2.371908</td>\n",
       "      <td>20.468943</td>\n",
       "      <td>2.371908</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>500</td>\n",
       "      <td>4.071167</td>\n",
       "      <td>34.122170</td>\n",
       "      <td>4.071167</td>\n",
       "      <td>1.471878</td>\n",
       "      <td>13.017926</td>\n",
       "      <td>1.471878</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>100</td>\n",
       "      <td>4.072762</td>\n",
       "      <td>34.915028</td>\n",
       "      <td>4.072762</td>\n",
       "      <td>2.403629</td>\n",
       "      <td>22.289497</td>\n",
       "      <td>2.403629</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>100</td>\n",
       "      <td>4.073814</td>\n",
       "      <td>35.290627</td>\n",
       "      <td>4.073814</td>\n",
       "      <td>3.315829</td>\n",
       "      <td>30.878201</td>\n",
       "      <td>3.315829</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>300</td>\n",
       "      <td>4.076564</td>\n",
       "      <td>35.689981</td>\n",
       "      <td>4.076564</td>\n",
       "      <td>3.074592</td>\n",
       "      <td>29.864370</td>\n",
       "      <td>3.074592</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>100</td>\n",
       "      <td>4.078272</td>\n",
       "      <td>35.770591</td>\n",
       "      <td>4.078272</td>\n",
       "      <td>2.976199</td>\n",
       "      <td>28.427572</td>\n",
       "      <td>2.976199</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>300</td>\n",
       "      <td>4.084844</td>\n",
       "      <td>34.850559</td>\n",
       "      <td>4.084844</td>\n",
       "      <td>2.880433</td>\n",
       "      <td>26.538426</td>\n",
       "      <td>2.880433</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>100</td>\n",
       "      <td>4.093836</td>\n",
       "      <td>34.865446</td>\n",
       "      <td>4.093836</td>\n",
       "      <td>3.008279</td>\n",
       "      <td>27.886187</td>\n",
       "      <td>3.008279</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>100</td>\n",
       "      <td>4.101981</td>\n",
       "      <td>39.034128</td>\n",
       "      <td>4.101981</td>\n",
       "      <td>4.241083</td>\n",
       "      <td>43.986153</td>\n",
       "      <td>4.241083</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "11            100  3.931706               33.633681                 3.931706   \n",
       "403           300  3.954406               34.150841                 3.954406   \n",
       "459           300  3.977251               33.501972                 3.977251   \n",
       "214           300  4.026696               34.355962                 4.026696   \n",
       "3             100  4.030043               34.276624                 4.030043   \n",
       "51            100  4.037873               35.138120                 4.037873   \n",
       "7             100  4.049980               36.534445                 4.049980   \n",
       "418           500  4.051798               35.326527                 4.051798   \n",
       "522           500  4.056374               34.480427                 4.056374   \n",
       "422           500  4.056850               35.321587                 4.056850   \n",
       "411           300  4.057975               34.304695                 4.057975   \n",
       "467           500  4.063852               34.379696                 4.063852   \n",
       "230           500  4.071167               34.122170                 4.071167   \n",
       "59            100  4.072762               34.915028                 4.072762   \n",
       "103           100  4.073814               35.290627                 4.073814   \n",
       "258           300  4.076564               35.689981                 4.076564   \n",
       "111           100  4.078272               35.770591                 4.078272   \n",
       "451           300  4.084844               34.850559                 4.084844   \n",
       "55            100  4.093836               34.865446                 4.093836   \n",
       "151           100  4.101981               39.034128                 4.101981   \n",
       "\n",
       "         loss  mean_squared_error  mean_absolute_error activation  batch_size  \\\n",
       "11   2.357946           22.745678             2.357946       relu          64   \n",
       "403  2.471902           22.945651             2.471902       relu         256   \n",
       "459  2.466416           22.071932             2.466416       relu         256   \n",
       "214  2.500297           23.679653             2.500297       relu         128   \n",
       "3    2.950520           27.676142             2.950520       relu          64   \n",
       "51   3.407935           32.280970             3.407935       relu          64   \n",
       "7    3.625712           35.389202             3.625712       relu          64   \n",
       "418  2.495266           23.992723             2.495266       relu         256   \n",
       "522  3.054852           27.582959             3.054852       relu         256   \n",
       "422  2.040443           19.908373             2.040443       relu         256   \n",
       "411  2.049821           19.318914             2.049821       relu         256   \n",
       "467  2.371908           20.468943             2.371908       relu         256   \n",
       "230  1.471878           13.017926             1.471878       relu         128   \n",
       "59   2.403629           22.289497             2.403629       relu          64   \n",
       "103  3.315829           30.878201             3.315829       relu          64   \n",
       "258  3.074592           29.864370             3.074592       relu         128   \n",
       "111  2.976199           28.427572             2.976199       relu          64   \n",
       "451  2.880433           26.538426             2.880433       relu         256   \n",
       "55   3.008279           27.886187             3.008279       relu          64   \n",
       "151  4.241083           43.986153             4.241083       relu          64   \n",
       "\n",
       "     dropout  epochs  filters_first  kernel_size loss padding  units_first  \n",
       "11       0.0     100             16            3  mae    same           32  \n",
       "403      0.0     300              4            3  mae    same           32  \n",
       "459      0.2     300             16            3  mae    same           32  \n",
       "214      0.0     300              8            3  mae    same           16  \n",
       "3        0.0     100              4            3  mae    same           32  \n",
       "51       0.2     100              4            3  mae    same           32  \n",
       "7        0.0     100              8            3  mae    same           32  \n",
       "418      0.0     500              4            3  mae    same           16  \n",
       "522      0.5     500             16            3  mae    same           16  \n",
       "422      0.0     500              8            3  mae    same           16  \n",
       "411      0.0     300             16            3  mae    same           32  \n",
       "467      0.2     500              4            3  mae    same           32  \n",
       "230      0.0     500              8            3  mae    same           16  \n",
       "59       0.2     100             16            3  mae    same           32  \n",
       "103      0.5     100              8            3  mae    same           32  \n",
       "258      0.2     300              4            3  mae    same           16  \n",
       "111      0.5     100             32            3  mae    same           32  \n",
       "451      0.2     300              4            3  mae    same           32  \n",
       "55       0.2     100              8            3  mae    same           32  \n",
       "151      0.8     100              8            3  mae    same           32  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cnn_rnn.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total number of trials was 2016'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Total number of trials was {r_cnn1.data.shape[0]+r_cnn2.data.shape[0]+r_rnn1.data.shape[0]+r_rnn2.data.shape[0]+r_cnn_rnn.data.shape[0]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning the selected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Check if adding more CNN layers improve the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_3l_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    MAX_SEQUENCE_LENGTH = x_train.shape[1]\n",
    "    \n",
    "    global embedding_matrix\n",
    "    \n",
    "    embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                     output_dim=embedding_matrix.shape[1],\n",
    "                     mask_zero=False,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=MAX_SEQUENCE_LENGTH,\n",
    "                     trainable=False)\n",
    "\n",
    "    line_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name=\"input\")\n",
    "    embedded_sequences = embedding_layer(line_input)\n",
    "    cnn = Conv1D(filters=params['filters_first'], kernel_size=params['kernel_size'], strides=1, \n",
    "                        padding=params['padding'],\n",
    "                        activation=params['activation'])(embedded_sequences)\n",
    "    cnn = AveragePooling1D(pool_size=2)(cnn)\n",
    "    cnn = Conv1D(filters=params['filters_second'], kernel_size=params['kernel_size'], strides=1, \n",
    "                        padding=params['padding'],\n",
    "                        activation=params['activation'])(cnn)\n",
    "    cnn = AveragePooling1D(pool_size=2)(cnn)\n",
    "    cnn = Conv1D(filters=params['filters_third'], kernel_size=params['kernel_size'], strides=1, \n",
    "                        padding=params['padding'],\n",
    "                        activation=params['activation'])(cnn)\n",
    "    cnn = AveragePooling1D(pool_size=2)(cnn)\n",
    "\n",
    "    cnn = Flatten()(cnn)\n",
    "\n",
    "    cnn = Dropout(params['dropout'])(cnn)\n",
    "\n",
    "    output = Dense(1, activation='linear')(cnn)\n",
    "\n",
    "    model = Model([line_input] , output) \n",
    "    \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.95, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=params['loss'],\n",
    "                  metrics=['mse', 'mae'])\n",
    "\n",
    "    callbacks_list = [\n",
    "        ReduceLROnPlateau( \n",
    "            monitor='loss',\n",
    "            min_lr=0.001,\n",
    "            factor=0.5,\n",
    "            verbose=1,\n",
    "            patience=10), \n",
    "    ]\n",
    "    \n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[x_val, y_val])\n",
    "    return out, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters_first':[4, 8, 16, 32],\n",
    "     'filters_second':[4, 8, 16, 32],\n",
    "     'filters_third':[4, 8, 16, 32],\n",
    "     'kernel_size':[3],\n",
    "     'batch_size': [64, 128, 256],\n",
    "     'epochs': [100, 300, 500],\n",
    "     'dropout': [0, 0.2, 0.5, 0.8],\n",
    "     'padding' : ['same',],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2304/2304 [6:09:37<00:00,  9.57s/it]\n"
     ]
    }
   ],
   "source": [
    "h_cnn3 = ta.Scan(x, y, params=p,\n",
    "            model=get_cnn_3l_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn3 = ta.Reporting(h_cnn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn3.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}cnn3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters_first</th>\n",
       "      <th>filters_second</th>\n",
       "      <th>filters_third</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>padding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>100</td>\n",
       "      <td>3.707282</td>\n",
       "      <td>33.828422</td>\n",
       "      <td>3.707282</td>\n",
       "      <td>3.633263</td>\n",
       "      <td>33.118604</td>\n",
       "      <td>3.633263</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>100</td>\n",
       "      <td>3.711038</td>\n",
       "      <td>33.189314</td>\n",
       "      <td>3.711038</td>\n",
       "      <td>4.149989</td>\n",
       "      <td>39.267885</td>\n",
       "      <td>4.149989</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>300</td>\n",
       "      <td>3.719381</td>\n",
       "      <td>33.000488</td>\n",
       "      <td>3.719381</td>\n",
       "      <td>3.527969</td>\n",
       "      <td>31.644216</td>\n",
       "      <td>3.527969</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>100</td>\n",
       "      <td>3.719963</td>\n",
       "      <td>33.659943</td>\n",
       "      <td>3.719963</td>\n",
       "      <td>3.674645</td>\n",
       "      <td>35.808758</td>\n",
       "      <td>3.674645</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>300</td>\n",
       "      <td>3.725108</td>\n",
       "      <td>32.606672</td>\n",
       "      <td>3.725108</td>\n",
       "      <td>3.623882</td>\n",
       "      <td>33.579163</td>\n",
       "      <td>3.623882</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>3.725483</td>\n",
       "      <td>31.951894</td>\n",
       "      <td>3.725483</td>\n",
       "      <td>2.860236</td>\n",
       "      <td>25.370698</td>\n",
       "      <td>2.860236</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>100</td>\n",
       "      <td>3.726642</td>\n",
       "      <td>32.659976</td>\n",
       "      <td>3.726642</td>\n",
       "      <td>3.349699</td>\n",
       "      <td>29.777566</td>\n",
       "      <td>3.349699</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>100</td>\n",
       "      <td>3.729649</td>\n",
       "      <td>33.569738</td>\n",
       "      <td>3.729649</td>\n",
       "      <td>3.638212</td>\n",
       "      <td>32.973961</td>\n",
       "      <td>3.638212</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>100</td>\n",
       "      <td>3.730466</td>\n",
       "      <td>34.122732</td>\n",
       "      <td>3.730466</td>\n",
       "      <td>3.696781</td>\n",
       "      <td>34.811666</td>\n",
       "      <td>3.696781</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>100</td>\n",
       "      <td>3.730949</td>\n",
       "      <td>32.958525</td>\n",
       "      <td>3.730949</td>\n",
       "      <td>3.490194</td>\n",
       "      <td>30.616546</td>\n",
       "      <td>3.490194</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>300</td>\n",
       "      <td>3.732240</td>\n",
       "      <td>32.403919</td>\n",
       "      <td>3.732240</td>\n",
       "      <td>3.136652</td>\n",
       "      <td>26.157617</td>\n",
       "      <td>3.136652</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>100</td>\n",
       "      <td>3.733081</td>\n",
       "      <td>33.152874</td>\n",
       "      <td>3.733081</td>\n",
       "      <td>3.341859</td>\n",
       "      <td>27.798279</td>\n",
       "      <td>3.341859</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>100</td>\n",
       "      <td>3.734895</td>\n",
       "      <td>32.440094</td>\n",
       "      <td>3.734895</td>\n",
       "      <td>3.265354</td>\n",
       "      <td>29.247597</td>\n",
       "      <td>3.265354</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>100</td>\n",
       "      <td>3.736302</td>\n",
       "      <td>32.440534</td>\n",
       "      <td>3.736302</td>\n",
       "      <td>3.419030</td>\n",
       "      <td>28.786326</td>\n",
       "      <td>3.419030</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100</td>\n",
       "      <td>3.736895</td>\n",
       "      <td>32.335611</td>\n",
       "      <td>3.736895</td>\n",
       "      <td>3.192701</td>\n",
       "      <td>28.732993</td>\n",
       "      <td>3.192701</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>500</td>\n",
       "      <td>3.737387</td>\n",
       "      <td>34.285938</td>\n",
       "      <td>3.737387</td>\n",
       "      <td>3.808629</td>\n",
       "      <td>35.800533</td>\n",
       "      <td>3.808629</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>100</td>\n",
       "      <td>3.737540</td>\n",
       "      <td>32.799572</td>\n",
       "      <td>3.737540</td>\n",
       "      <td>3.445231</td>\n",
       "      <td>30.721064</td>\n",
       "      <td>3.445231</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>100</td>\n",
       "      <td>3.738282</td>\n",
       "      <td>33.443283</td>\n",
       "      <td>3.738282</td>\n",
       "      <td>3.925786</td>\n",
       "      <td>37.369453</td>\n",
       "      <td>3.925786</td>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>0.8</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>100</td>\n",
       "      <td>3.741192</td>\n",
       "      <td>34.161266</td>\n",
       "      <td>3.741192</td>\n",
       "      <td>4.156262</td>\n",
       "      <td>39.679939</td>\n",
       "      <td>4.156262</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>100</td>\n",
       "      <td>3.741381</td>\n",
       "      <td>32.653267</td>\n",
       "      <td>3.741381</td>\n",
       "      <td>3.616182</td>\n",
       "      <td>32.245564</td>\n",
       "      <td>3.616182</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "418            100  3.707282               33.828422                 3.707282   \n",
       "611            100  3.711038               33.189314                 3.711038   \n",
       "1990           300  3.719381               33.000488                 3.719381   \n",
       "1012           100  3.719963               33.659943                 3.719963   \n",
       "1029           300  3.725108               32.606672                 3.725108   \n",
       "11             100  3.725483               31.951894                 3.725483   \n",
       "199            100  3.726642               32.659976                 3.726642   \n",
       "414            100  3.729649               33.569738                 3.729649   \n",
       "1198           100  3.730466               34.122732                 3.730466   \n",
       "406            100  3.730949               32.958525                 3.730949   \n",
       "1991           300  3.732240               32.403919                 3.732240   \n",
       "403            100  3.733081               33.152874                 3.733081   \n",
       "797            100  3.734895               32.440094                 3.734895   \n",
       "1203           100  3.736302               32.440534                 3.736302   \n",
       "22             100  3.736895               32.335611                 3.736895   \n",
       "1856           500  3.737387               34.285938                 3.737387   \n",
       "221            100  3.737540               32.799572                 3.737540   \n",
       "587            100  3.738282               33.443283                 3.738282   \n",
       "1197           100  3.741192               34.161266                 3.741192   \n",
       "967            100  3.741381               32.653267                 3.741381   \n",
       "\n",
       "          loss  mean_squared_error  mean_absolute_error activation  \\\n",
       "418   3.633263           33.118604             3.633263       relu   \n",
       "611   4.149989           39.267885             4.149989       relu   \n",
       "1990  3.527969           31.644216             3.527969       relu   \n",
       "1012  3.674645           35.808758             3.674645       relu   \n",
       "1029  3.623882           33.579163             3.623882       relu   \n",
       "11    2.860236           25.370698             2.860236       relu   \n",
       "199   3.349699           29.777566             3.349699       relu   \n",
       "414   3.638212           32.973961             3.638212       relu   \n",
       "1198  3.696781           34.811666             3.696781       relu   \n",
       "406   3.490194           30.616546             3.490194       relu   \n",
       "1991  3.136652           26.157617             3.136652       relu   \n",
       "403   3.341859           27.798279             3.341859       relu   \n",
       "797   3.265354           29.247597             3.265354       relu   \n",
       "1203  3.419030           28.786326             3.419030       relu   \n",
       "22    3.192701           28.732993             3.192701       relu   \n",
       "1856  3.808629           35.800533             3.808629       relu   \n",
       "221   3.445231           30.721064             3.445231       relu   \n",
       "587   3.925786           37.369453             3.925786       relu   \n",
       "1197  4.156262           39.679939             4.156262       relu   \n",
       "967   3.616182           32.245564             3.616182       relu   \n",
       "\n",
       "      batch_size  dropout  epochs  filters_first  filters_second  \\\n",
       "418           64      0.5     100             16               4   \n",
       "611           64      0.8     100             16               4   \n",
       "1990         256      0.5     300              4               8   \n",
       "1012         128      0.2     100             32               8   \n",
       "1029         128      0.2     300              4               8   \n",
       "11            64      0.0     100              4              16   \n",
       "199           64      0.2     100              4               8   \n",
       "414           64      0.5     100              8              32   \n",
       "1198         128      0.5     100             16              32   \n",
       "406           64      0.5     100              8               8   \n",
       "1991         256      0.5     300              4               8   \n",
       "403           64      0.5     100              8               4   \n",
       "797          128      0.0     100              8              32   \n",
       "1203         128      0.5     100             32               4   \n",
       "22            64      0.0     100              8               8   \n",
       "1856         256      0.2     500              4               4   \n",
       "221           64      0.2     100              8              32   \n",
       "587           64      0.8     100              4              16   \n",
       "1197         128      0.5     100             16              32   \n",
       "967          128      0.2     100              4               8   \n",
       "\n",
       "      filters_third  kernel_size loss padding  \n",
       "418              16            3  mae    same  \n",
       "611              32            3  mae    same  \n",
       "1990             16            3  mae    same  \n",
       "1012              4            3  mae    same  \n",
       "1029              8            3  mae    same  \n",
       "11               32            3  mae    same  \n",
       "199              32            3  mae    same  \n",
       "414              16            3  mae    same  \n",
       "1198             16            3  mae    same  \n",
       "406              16            3  mae    same  \n",
       "1991             32            3  mae    same  \n",
       "403              32            3  mae    same  \n",
       "797               8            3  mae    same  \n",
       "1203             32            3  mae    same  \n",
       "22               16            3  mae    same  \n",
       "1856              4            3  mae    same  \n",
       "221               8            3  mae    same  \n",
       "587              32            3  mae    same  \n",
       "1197              8            3  mae    same  \n",
       "967              32            3  mae    same  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cnn3.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- CNN with 3 layers provide worse accuracy than with 2 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Optimize the 2-layer CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_2l_optimize_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    MAX_SEQUENCE_LENGTH = x_train.shape[1]\n",
    "    \n",
    "    global embedding_matrix\n",
    "    \n",
    "    embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                     output_dim=embedding_matrix.shape[1],\n",
    "                     mask_zero=False,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=MAX_SEQUENCE_LENGTH,\n",
    "                     trainable=False)\n",
    "\n",
    "    line_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name=\"input\")\n",
    "    embedded_sequences = embedding_layer(line_input)\n",
    "    cnn = Conv1D(filters=params['filters_first'], kernel_size=params['kernel_size'], strides=1, \n",
    "                        padding=params['padding'],\n",
    "                        activation=params['activation'])(embedded_sequences)\n",
    "    cnn = params['pooling'](pool_size=2)(cnn)\n",
    "    cnn = Conv1D(filters=params['filters_second'], kernel_size=params['kernel_size'], strides=1, \n",
    "                        padding=params['padding'],\n",
    "                        activation=params['activation'])(cnn)\n",
    "    cnn = AveragePooling1D(pool_size=2)(cnn)\n",
    "    \n",
    "    if params['global_pool'] is False or params['global_pool'] is None:\n",
    "        cnn = Flatten()(cnn)\n",
    "\n",
    "    cnn = Dropout(params['dropout'])(cnn)\n",
    "    \n",
    "    if params['global_pool'] is not None:\n",
    "        cnn = params['global_pool']()(cnn)\n",
    "\n",
    "    output = Dense(1, activation='linear')(cnn)\n",
    "\n",
    "    model = Model([line_input] , output) \n",
    "    \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.95, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=params['loss'],\n",
    "                  metrics=['mse', 'mae'])\n",
    "\n",
    "    callbacks_list = [\n",
    "        ReduceLROnPlateau( \n",
    "            monitor='loss',\n",
    "            min_lr=0.001,\n",
    "            factor=0.5,\n",
    "            verbose=1,\n",
    "            patience=10), \n",
    "    ]\n",
    "    \n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[x_val, y_val])\n",
    "    return out, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Round 1:**\n",
    "\n",
    "Goals:\n",
    "- try different number of filters\n",
    "- it seems that it is better to have larger batch size - try 200 (between 128 and 256)\n",
    "- try more dropout rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters_first':[4, 8, 10, 12, 16, 32],\n",
    "     'filters_second':[4, 8, 10, 12, 16, 32],\n",
    "     'global_pool' : [None],\n",
    "     'pooling' : [AveragePooling1D],\n",
    "     'kernel_size' : [3],\n",
    "     'batch_size': [128, 200, 256],\n",
    "     'epochs': [300, 400, 500],\n",
    "     'dropout': [0.2, 0.3, 0.5, 0.6, 0.8],\n",
    "     'padding' : ['same', ],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1620/1620 [3:37:14<00:00,  8.37s/it]\n"
     ]
    }
   ],
   "source": [
    "h_cnn2_opt = ta.Scan(x, y, params=p,\n",
    "            model=get_cnn_2l_optimize_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt1 = ta.Reporting(h_cnn2_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt1.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}cnn2_opt1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters_first</th>\n",
       "      <th>filters_second</th>\n",
       "      <th>global_pool</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>padding</th>\n",
       "      <th>pooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>500</td>\n",
       "      <td>3.681899</td>\n",
       "      <td>31.878607</td>\n",
       "      <td>3.681899</td>\n",
       "      <td>3.237408</td>\n",
       "      <td>27.569960</td>\n",
       "      <td>3.237408</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>400</td>\n",
       "      <td>3.683891</td>\n",
       "      <td>32.603790</td>\n",
       "      <td>3.683891</td>\n",
       "      <td>3.973372</td>\n",
       "      <td>36.937891</td>\n",
       "      <td>3.973372</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.8</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>400</td>\n",
       "      <td>3.690797</td>\n",
       "      <td>31.755579</td>\n",
       "      <td>3.690797</td>\n",
       "      <td>3.547464</td>\n",
       "      <td>31.432706</td>\n",
       "      <td>3.547464</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>300</td>\n",
       "      <td>3.693576</td>\n",
       "      <td>32.782413</td>\n",
       "      <td>3.693576</td>\n",
       "      <td>3.805458</td>\n",
       "      <td>33.693159</td>\n",
       "      <td>3.805458</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.6</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>400</td>\n",
       "      <td>3.694512</td>\n",
       "      <td>32.586864</td>\n",
       "      <td>3.694512</td>\n",
       "      <td>3.727040</td>\n",
       "      <td>35.877683</td>\n",
       "      <td>3.727040</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>300</td>\n",
       "      <td>3.697991</td>\n",
       "      <td>32.613914</td>\n",
       "      <td>3.697991</td>\n",
       "      <td>3.662649</td>\n",
       "      <td>30.834937</td>\n",
       "      <td>3.662649</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>300</td>\n",
       "      <td>3.698331</td>\n",
       "      <td>32.667267</td>\n",
       "      <td>3.698331</td>\n",
       "      <td>3.531215</td>\n",
       "      <td>32.913167</td>\n",
       "      <td>3.531215</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>300</td>\n",
       "      <td>3.698541</td>\n",
       "      <td>31.538437</td>\n",
       "      <td>3.698541</td>\n",
       "      <td>3.203499</td>\n",
       "      <td>26.931889</td>\n",
       "      <td>3.203499</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>500</td>\n",
       "      <td>3.700402</td>\n",
       "      <td>32.121761</td>\n",
       "      <td>3.700402</td>\n",
       "      <td>3.484164</td>\n",
       "      <td>31.160520</td>\n",
       "      <td>3.484164</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>300</td>\n",
       "      <td>3.704948</td>\n",
       "      <td>33.280777</td>\n",
       "      <td>3.704948</td>\n",
       "      <td>3.762641</td>\n",
       "      <td>35.229409</td>\n",
       "      <td>3.762641</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>300</td>\n",
       "      <td>3.705224</td>\n",
       "      <td>32.218586</td>\n",
       "      <td>3.705224</td>\n",
       "      <td>3.509750</td>\n",
       "      <td>31.157819</td>\n",
       "      <td>3.509750</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>300</td>\n",
       "      <td>3.705892</td>\n",
       "      <td>32.118858</td>\n",
       "      <td>3.705892</td>\n",
       "      <td>3.369336</td>\n",
       "      <td>29.985886</td>\n",
       "      <td>3.369336</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>400</td>\n",
       "      <td>3.706074</td>\n",
       "      <td>31.993952</td>\n",
       "      <td>3.706074</td>\n",
       "      <td>3.317297</td>\n",
       "      <td>28.129589</td>\n",
       "      <td>3.317297</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>300</td>\n",
       "      <td>3.708439</td>\n",
       "      <td>32.383209</td>\n",
       "      <td>3.708439</td>\n",
       "      <td>3.541814</td>\n",
       "      <td>29.023105</td>\n",
       "      <td>3.541814</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>300</td>\n",
       "      <td>3.708802</td>\n",
       "      <td>32.515958</td>\n",
       "      <td>3.708802</td>\n",
       "      <td>3.598302</td>\n",
       "      <td>29.992510</td>\n",
       "      <td>3.598302</td>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>300</td>\n",
       "      <td>3.709649</td>\n",
       "      <td>32.010612</td>\n",
       "      <td>3.709649</td>\n",
       "      <td>3.614288</td>\n",
       "      <td>31.750643</td>\n",
       "      <td>3.614288</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>500</td>\n",
       "      <td>3.712765</td>\n",
       "      <td>32.796055</td>\n",
       "      <td>3.712765</td>\n",
       "      <td>3.320469</td>\n",
       "      <td>27.961654</td>\n",
       "      <td>3.320469</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>300</td>\n",
       "      <td>3.712876</td>\n",
       "      <td>33.238411</td>\n",
       "      <td>3.712876</td>\n",
       "      <td>3.780422</td>\n",
       "      <td>36.092990</td>\n",
       "      <td>3.780422</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>500</td>\n",
       "      <td>3.713444</td>\n",
       "      <td>34.480682</td>\n",
       "      <td>3.713444</td>\n",
       "      <td>3.894425</td>\n",
       "      <td>34.234131</td>\n",
       "      <td>3.894425</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>300</td>\n",
       "      <td>3.713470</td>\n",
       "      <td>33.345482</td>\n",
       "      <td>3.713470</td>\n",
       "      <td>3.920319</td>\n",
       "      <td>34.411582</td>\n",
       "      <td>3.920319</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "1152           500  3.681899               31.878607                 3.681899   \n",
       "1010           400  3.683891               32.603790                 3.683891   \n",
       "1442           400  3.690797               31.755579                 3.690797   \n",
       "331            300  3.693576               32.782413                 3.693576   \n",
       "794            400  3.694512               32.586864                 3.694512   \n",
       "763            300  3.697991               32.613914                 3.697991   \n",
       "552            300  3.698331               32.667267                 3.698331   \n",
       "1081           300  3.698541               31.538437                 3.698541   \n",
       "720            500  3.700402               32.121761                 3.700402   \n",
       "867            300  3.704948               33.280777                 3.704948   \n",
       "871            300  3.705224               32.218586                 3.705224   \n",
       "1203           300  3.705892               32.118858                 3.705892   \n",
       "902            400  3.706074               31.993952                 3.706074   \n",
       "759            300  3.708439               32.383209                 3.708439   \n",
       "217            300  3.708802               32.515958                 3.708802   \n",
       "764            300  3.709649               32.010612                 3.709649   \n",
       "612            500  3.712765               32.796055                 3.712765   \n",
       "878            300  3.712876               33.238411                 3.712876   \n",
       "1374           500  3.713444               34.480682                 3.713444   \n",
       "1320           300  3.713470               33.345482                 3.713470   \n",
       "\n",
       "          loss  mean_squared_error  mean_absolute_error activation  \\\n",
       "1152  3.237408           27.569960             3.237408       relu   \n",
       "1010  3.973372           36.937891             3.973372       relu   \n",
       "1442  3.547464           31.432706             3.547464       relu   \n",
       "331   3.805458           33.693159             3.805458       relu   \n",
       "794   3.727040           35.877683             3.727040       relu   \n",
       "763   3.662649           30.834937             3.662649       relu   \n",
       "552   3.531215           32.913167             3.531215       relu   \n",
       "1081  3.203499           26.931889             3.203499       relu   \n",
       "720   3.484164           31.160520             3.484164       relu   \n",
       "867   3.762641           35.229409             3.762641       relu   \n",
       "871   3.509750           31.157819             3.509750       relu   \n",
       "1203  3.369336           29.985886             3.369336       relu   \n",
       "902   3.317297           28.129589             3.317297       relu   \n",
       "759   3.541814           29.023105             3.541814       relu   \n",
       "217   3.598302           29.992510             3.598302       relu   \n",
       "764   3.614288           31.750643             3.614288       relu   \n",
       "612   3.320469           27.961654             3.320469       relu   \n",
       "878   3.780422           36.092990             3.780422       relu   \n",
       "1374  3.894425           34.234131             3.894425       relu   \n",
       "1320  3.920319           34.411582             3.920319       relu   \n",
       "\n",
       "      batch_size  dropout  epochs  filters_first  filters_second  global_pool  \\\n",
       "1152         256      0.2     500              4               4        False   \n",
       "1010         200      0.8     400              4              10        False   \n",
       "1442         256      0.6     400              4              10        False   \n",
       "331          128      0.6     300              8               8        False   \n",
       "794          200      0.5     400              4              10        False   \n",
       "763          200      0.5     300              8               8        False   \n",
       "552          200      0.2     300             10               4        False   \n",
       "1081         256      0.2     300              4               8        False   \n",
       "720          200      0.3     500              4               4        False   \n",
       "867          200      0.6     300              4              12        False   \n",
       "871          200      0.6     300              8               8        False   \n",
       "1203         256      0.3     300             10              12        False   \n",
       "902          200      0.6     400              4              10        False   \n",
       "759          200      0.5     300              4              12        False   \n",
       "217          128      0.5     300              4               8        False   \n",
       "764          200      0.5     300              8              10        False   \n",
       "612          200      0.2     500              4               4        False   \n",
       "878          200      0.6     300             10              10        False   \n",
       "1374         256      0.5     500              8               4        False   \n",
       "1320         256      0.5     300             16               4        False   \n",
       "\n",
       "      kernel_size loss padding  \\\n",
       "1152            3  mae    same   \n",
       "1010            3  mae    same   \n",
       "1442            3  mae    same   \n",
       "331             3  mae    same   \n",
       "794             3  mae    same   \n",
       "763             3  mae    same   \n",
       "552             3  mae    same   \n",
       "1081            3  mae    same   \n",
       "720             3  mae    same   \n",
       "867             3  mae    same   \n",
       "871             3  mae    same   \n",
       "1203            3  mae    same   \n",
       "902             3  mae    same   \n",
       "759             3  mae    same   \n",
       "217             3  mae    same   \n",
       "764             3  mae    same   \n",
       "612             3  mae    same   \n",
       "878             3  mae    same   \n",
       "1374            3  mae    same   \n",
       "1320            3  mae    same   \n",
       "\n",
       "                                              pooling  \n",
       "1152  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1010  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1442  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "331   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "794   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "763   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "552   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1081  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "720   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "867   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "871   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1203  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "902   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "759   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "217   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "764   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "612   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "878   <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1374  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1320  <class 'keras.layers.pooling.AveragePooling1D'>  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cnn2_opt1.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- a smaller number of filters seems to perform better\n",
    "- larger batch sizes (200 and 256) seem to perform better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Round 2:**\n",
    "\n",
    "Goals: \n",
    "- reduce the number of filters to max. 12\n",
    "- remove 128 from batch sizes\n",
    "- try max pooling \n",
    "- try valid padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters_first':[4, 8, 10, 12],\n",
    "     'filters_second':[4, 8, 10, 12],\n",
    "     'global_pool' : [None],\n",
    "     'pooling' : [MaxPooling1D],\n",
    "     'kernel_size' : [3],\n",
    "     'batch_size': [200, 256],\n",
    "     'epochs': [300, 400, 500],\n",
    "     'dropout': [0.2, 0.3, 0.5, 0.6, 0.8],\n",
    "     'padding' : ['same', 'valid' ],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 960/960 [1:55:12<00:00,  8.41s/it]\n"
     ]
    }
   ],
   "source": [
    "h_cnn2_opt2 = ta.Scan(x, y, params=p,\n",
    "            model=get_cnn_2l_optimize_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt2 = ta.Reporting(h_cnn2_opt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt2.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}cnn2_opt2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters_first</th>\n",
       "      <th>filters_second</th>\n",
       "      <th>global_pool</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>padding</th>\n",
       "      <th>pooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>300</td>\n",
       "      <td>3.680320</td>\n",
       "      <td>32.193874</td>\n",
       "      <td>3.680320</td>\n",
       "      <td>3.317353</td>\n",
       "      <td>27.581006</td>\n",
       "      <td>3.317353</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>300</td>\n",
       "      <td>3.681606</td>\n",
       "      <td>32.817875</td>\n",
       "      <td>3.681606</td>\n",
       "      <td>3.442568</td>\n",
       "      <td>30.893156</td>\n",
       "      <td>3.442568</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>500</td>\n",
       "      <td>3.682738</td>\n",
       "      <td>32.364494</td>\n",
       "      <td>3.682738</td>\n",
       "      <td>3.213886</td>\n",
       "      <td>26.902519</td>\n",
       "      <td>3.213886</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>300</td>\n",
       "      <td>3.688679</td>\n",
       "      <td>32.420910</td>\n",
       "      <td>3.688679</td>\n",
       "      <td>3.481388</td>\n",
       "      <td>31.761607</td>\n",
       "      <td>3.481388</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>300</td>\n",
       "      <td>3.688787</td>\n",
       "      <td>31.680845</td>\n",
       "      <td>3.688787</td>\n",
       "      <td>3.334398</td>\n",
       "      <td>31.625212</td>\n",
       "      <td>3.334398</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>300</td>\n",
       "      <td>3.698598</td>\n",
       "      <td>32.061123</td>\n",
       "      <td>3.698598</td>\n",
       "      <td>3.249271</td>\n",
       "      <td>26.941509</td>\n",
       "      <td>3.249271</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>400</td>\n",
       "      <td>3.699495</td>\n",
       "      <td>32.694237</td>\n",
       "      <td>3.699495</td>\n",
       "      <td>3.745995</td>\n",
       "      <td>31.725996</td>\n",
       "      <td>3.745995</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>400</td>\n",
       "      <td>3.701450</td>\n",
       "      <td>32.939861</td>\n",
       "      <td>3.701450</td>\n",
       "      <td>3.640594</td>\n",
       "      <td>31.601640</td>\n",
       "      <td>3.640594</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.8</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>500</td>\n",
       "      <td>3.701734</td>\n",
       "      <td>32.610508</td>\n",
       "      <td>3.701734</td>\n",
       "      <td>3.574619</td>\n",
       "      <td>30.611063</td>\n",
       "      <td>3.574619</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>400</td>\n",
       "      <td>3.704964</td>\n",
       "      <td>31.849390</td>\n",
       "      <td>3.704964</td>\n",
       "      <td>3.360170</td>\n",
       "      <td>29.380457</td>\n",
       "      <td>3.360170</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>500</td>\n",
       "      <td>3.706840</td>\n",
       "      <td>33.104603</td>\n",
       "      <td>3.706840</td>\n",
       "      <td>3.709602</td>\n",
       "      <td>35.568424</td>\n",
       "      <td>3.709602</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>400</td>\n",
       "      <td>3.712395</td>\n",
       "      <td>33.894203</td>\n",
       "      <td>3.712395</td>\n",
       "      <td>3.820155</td>\n",
       "      <td>33.678115</td>\n",
       "      <td>3.820155</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>valid</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>300</td>\n",
       "      <td>3.712843</td>\n",
       "      <td>32.847038</td>\n",
       "      <td>3.712843</td>\n",
       "      <td>3.704293</td>\n",
       "      <td>34.119007</td>\n",
       "      <td>3.704293</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>300</td>\n",
       "      <td>3.716967</td>\n",
       "      <td>32.292988</td>\n",
       "      <td>3.716967</td>\n",
       "      <td>3.361130</td>\n",
       "      <td>28.972028</td>\n",
       "      <td>3.361130</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>500</td>\n",
       "      <td>3.717058</td>\n",
       "      <td>34.294350</td>\n",
       "      <td>3.717058</td>\n",
       "      <td>4.015197</td>\n",
       "      <td>37.437655</td>\n",
       "      <td>4.015197</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>valid</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>300</td>\n",
       "      <td>3.717131</td>\n",
       "      <td>33.835915</td>\n",
       "      <td>3.717131</td>\n",
       "      <td>3.906982</td>\n",
       "      <td>38.725612</td>\n",
       "      <td>3.906982</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>300</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>valid</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>300</td>\n",
       "      <td>3.718021</td>\n",
       "      <td>34.164711</td>\n",
       "      <td>3.718021</td>\n",
       "      <td>4.114232</td>\n",
       "      <td>39.620125</td>\n",
       "      <td>4.114232</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.8</td>\n",
       "      <td>300</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>400</td>\n",
       "      <td>3.718428</td>\n",
       "      <td>32.594402</td>\n",
       "      <td>3.718428</td>\n",
       "      <td>4.054341</td>\n",
       "      <td>35.720493</td>\n",
       "      <td>4.054341</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>400</td>\n",
       "      <td>3.720475</td>\n",
       "      <td>33.491081</td>\n",
       "      <td>3.720475</td>\n",
       "      <td>4.023314</td>\n",
       "      <td>38.537283</td>\n",
       "      <td>4.023314</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>valid</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>300</td>\n",
       "      <td>3.721508</td>\n",
       "      <td>32.916500</td>\n",
       "      <td>3.721508</td>\n",
       "      <td>3.406961</td>\n",
       "      <td>29.646699</td>\n",
       "      <td>3.406961</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "104           300  3.680320               32.193874                 3.680320   \n",
       "490           300  3.681606               32.817875                 3.681606   \n",
       "552           500  3.682738               32.364494                 3.682738   \n",
       "684           300  3.688679               32.420910                 3.688679   \n",
       "694           300  3.688787               31.680845                 3.688787   \n",
       "588           300  3.698598               32.061123                 3.698598   \n",
       "720           400  3.699495               32.694237                 3.699495   \n",
       "422           400  3.701450               32.939861                 3.701450   \n",
       "736           500  3.701734               32.610508                 3.701734   \n",
       "806           400  3.704964               31.849390                 3.704964   \n",
       "640           500  3.706840               33.104603                 3.706840   \n",
       "831           400  3.712395               33.894203                 3.712395   \n",
       "698           300  3.712843               32.847038                 3.712843   \n",
       "790           300  3.716967               32.292988                 3.716967   \n",
       "839           500  3.717058               34.294350                 3.717058   \n",
       "121           300  3.717131               33.835915                 3.717131   \n",
       "398           300  3.718021               34.164711                 3.718021   \n",
       "918           400  3.718428               32.594402                 3.718428   \n",
       "811           400  3.720475               33.491081                 3.720475   \n",
       "196           300  3.721508               32.916500                 3.721508   \n",
       "\n",
       "         loss  mean_squared_error  mean_absolute_error activation  batch_size  \\\n",
       "104  3.317353           27.581006             3.317353       relu         200   \n",
       "490  3.442568           30.893156             3.442568       relu         256   \n",
       "552  3.213886           26.902519             3.213886       relu         256   \n",
       "684  3.481388           31.761607             3.481388       relu         256   \n",
       "694  3.334398           31.625212             3.334398       relu         256   \n",
       "588  3.249271           26.941509             3.249271       relu         256   \n",
       "720  3.745995           31.725996             3.745995       relu         256   \n",
       "422  3.640594           31.601640             3.640594       relu         200   \n",
       "736  3.574619           30.611063             3.574619       relu         256   \n",
       "806  3.360170           29.380457             3.360170       relu         256   \n",
       "640  3.709602           35.568424             3.709602       relu         256   \n",
       "831  3.820155           33.678115             3.820155       relu         256   \n",
       "698  3.704293           34.119007             3.704293       relu         256   \n",
       "790  3.361130           28.972028             3.361130       relu         256   \n",
       "839  4.015197           37.437655             4.015197       relu         256   \n",
       "121  3.906982           38.725612             3.906982       relu         200   \n",
       "398  4.114232           39.620125             4.114232       relu         200   \n",
       "918  4.054341           35.720493             4.054341       relu         256   \n",
       "811  4.023314           38.537283             4.023314       relu         256   \n",
       "196  3.406961           29.646699             3.406961       relu         200   \n",
       "\n",
       "     dropout  epochs  filters_first  filters_second  global_pool  kernel_size  \\\n",
       "104      0.3     300              8               4        False            3   \n",
       "490      0.2     300              8               8        False            3   \n",
       "552      0.2     500              8               4        False            3   \n",
       "684      0.5     300              8              10        False            3   \n",
       "694      0.5     300             10              12        False            3   \n",
       "588      0.3     300              8              10        False            3   \n",
       "720      0.5     400             10               4        False            3   \n",
       "422      0.8     400              4              12        False            3   \n",
       "736      0.5     500              4               4        False            3   \n",
       "806      0.6     400              4              12        False            3   \n",
       "640      0.3     500              4               4        False            3   \n",
       "831      0.6     400             12              12        False            3   \n",
       "698      0.5     300             12               8        False            3   \n",
       "790      0.6     300             10              12        False            3   \n",
       "839      0.6     500              4              12        False            3   \n",
       "121      0.3     300             12               4        False            3   \n",
       "398      0.8     300              8              12        False            3   \n",
       "918      0.8     400             10              12        False            3   \n",
       "811      0.6     400              8               8        False            3   \n",
       "196      0.5     300              4              10        False            3   \n",
       "\n",
       "    loss padding                                      pooling  \n",
       "104  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "490  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "552  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "684  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "694  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "588  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "720  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "422  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "736  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "806  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "640  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "831  mae   valid  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "698  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "790  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "839  mae   valid  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "121  mae   valid  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "398  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "918  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "811  mae   valid  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "196  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cnn2_opt2.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- the same padding seems better than valid padding\n",
    "- max and average over-time pooling seem to perform with very similar accuracy (max pooling seem to work a little bit better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Round 3:**\n",
    "\n",
    "Goals:\n",
    "- continue comparing max and average over-time pooling\n",
    "- try to use global pooling instead of flattening the feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters_first':[4, 8, 10, 12],\n",
    "     'filters_second':[4, 8, 10, 12],\n",
    "     'global_pool' : [GlobalAveragePooling1D, GlobalMaxPooling1D],\n",
    "     'pooling' : [AveragePooling1D, MaxPooling1D],\n",
    "     'kernel_size' : [3],\n",
    "     'batch_size': [200, 256],\n",
    "     'epochs': [300, 400, 500],\n",
    "     'dropout': [0.2, 0.3, 0.5, 0.6, 0.8],\n",
    "     'padding' : ['same', ],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1920/1920 [3:51:53<00:00,  8.63s/it]\n"
     ]
    }
   ],
   "source": [
    "h_cnn2_opt3 = ta.Scan(x, y, params=p,\n",
    "            model=get_cnn_2l_optimize_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt3 = ta.Reporting(h_cnn2_opt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt3.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}cnn2_opt3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters_first</th>\n",
       "      <th>filters_second</th>\n",
       "      <th>global_pool</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>padding</th>\n",
       "      <th>pooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>500</td>\n",
       "      <td>3.665162</td>\n",
       "      <td>30.928324</td>\n",
       "      <td>3.665162</td>\n",
       "      <td>3.351209</td>\n",
       "      <td>28.824132</td>\n",
       "      <td>3.351209</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>400</td>\n",
       "      <td>3.688706</td>\n",
       "      <td>32.959915</td>\n",
       "      <td>3.688706</td>\n",
       "      <td>3.439334</td>\n",
       "      <td>33.444127</td>\n",
       "      <td>3.439334</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>400</td>\n",
       "      <td>3.691783</td>\n",
       "      <td>32.888565</td>\n",
       "      <td>3.691783</td>\n",
       "      <td>3.589276</td>\n",
       "      <td>32.428992</td>\n",
       "      <td>3.589276</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>400</td>\n",
       "      <td>3.694067</td>\n",
       "      <td>32.333881</td>\n",
       "      <td>3.694067</td>\n",
       "      <td>3.217701</td>\n",
       "      <td>27.858132</td>\n",
       "      <td>3.217701</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>300</td>\n",
       "      <td>3.695072</td>\n",
       "      <td>32.788326</td>\n",
       "      <td>3.695072</td>\n",
       "      <td>3.756492</td>\n",
       "      <td>34.210275</td>\n",
       "      <td>3.756492</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>400</td>\n",
       "      <td>3.695392</td>\n",
       "      <td>31.876768</td>\n",
       "      <td>3.695392</td>\n",
       "      <td>3.624677</td>\n",
       "      <td>31.619041</td>\n",
       "      <td>3.624677</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>400</td>\n",
       "      <td>3.696461</td>\n",
       "      <td>32.876373</td>\n",
       "      <td>3.696461</td>\n",
       "      <td>3.756115</td>\n",
       "      <td>34.317944</td>\n",
       "      <td>3.756115</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>400</td>\n",
       "      <td>3.696624</td>\n",
       "      <td>32.634186</td>\n",
       "      <td>3.696624</td>\n",
       "      <td>3.470826</td>\n",
       "      <td>31.502185</td>\n",
       "      <td>3.470826</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>300</td>\n",
       "      <td>3.699656</td>\n",
       "      <td>32.943523</td>\n",
       "      <td>3.699656</td>\n",
       "      <td>3.563812</td>\n",
       "      <td>33.397288</td>\n",
       "      <td>3.563812</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>300</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>500</td>\n",
       "      <td>3.699997</td>\n",
       "      <td>33.148014</td>\n",
       "      <td>3.699997</td>\n",
       "      <td>3.706141</td>\n",
       "      <td>34.206569</td>\n",
       "      <td>3.706141</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>500</td>\n",
       "      <td>3.700149</td>\n",
       "      <td>32.162991</td>\n",
       "      <td>3.700149</td>\n",
       "      <td>3.577147</td>\n",
       "      <td>31.404374</td>\n",
       "      <td>3.577147</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>500</td>\n",
       "      <td>3.701254</td>\n",
       "      <td>32.502342</td>\n",
       "      <td>3.701254</td>\n",
       "      <td>3.465750</td>\n",
       "      <td>30.054381</td>\n",
       "      <td>3.465750</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>400</td>\n",
       "      <td>3.701380</td>\n",
       "      <td>33.022202</td>\n",
       "      <td>3.701380</td>\n",
       "      <td>3.451596</td>\n",
       "      <td>31.207057</td>\n",
       "      <td>3.451596</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>300</td>\n",
       "      <td>3.702021</td>\n",
       "      <td>32.039867</td>\n",
       "      <td>3.702021</td>\n",
       "      <td>3.301353</td>\n",
       "      <td>29.459223</td>\n",
       "      <td>3.301353</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>300</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>400</td>\n",
       "      <td>3.702948</td>\n",
       "      <td>32.538918</td>\n",
       "      <td>3.702948</td>\n",
       "      <td>3.522184</td>\n",
       "      <td>32.084558</td>\n",
       "      <td>3.522184</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>500</td>\n",
       "      <td>3.703192</td>\n",
       "      <td>32.063816</td>\n",
       "      <td>3.703192</td>\n",
       "      <td>3.335393</td>\n",
       "      <td>28.492811</td>\n",
       "      <td>3.335393</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>400</td>\n",
       "      <td>3.703836</td>\n",
       "      <td>33.105751</td>\n",
       "      <td>3.703836</td>\n",
       "      <td>3.722057</td>\n",
       "      <td>36.172866</td>\n",
       "      <td>3.722057</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>400</td>\n",
       "      <td>3.705340</td>\n",
       "      <td>31.980204</td>\n",
       "      <td>3.705340</td>\n",
       "      <td>3.400247</td>\n",
       "      <td>30.965496</td>\n",
       "      <td>3.400247</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.AveragePooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>500</td>\n",
       "      <td>3.705462</td>\n",
       "      <td>31.864922</td>\n",
       "      <td>3.705462</td>\n",
       "      <td>3.772157</td>\n",
       "      <td>33.234667</td>\n",
       "      <td>3.772157</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>500</td>\n",
       "      <td>3.705805</td>\n",
       "      <td>33.054108</td>\n",
       "      <td>3.705805</td>\n",
       "      <td>3.556864</td>\n",
       "      <td>31.799229</td>\n",
       "      <td>3.556864</td>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>0.6</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "717            500  3.665162               30.928324                 3.665162   \n",
       "1631           400  3.688706               32.959915                 3.688706   \n",
       "308            400  3.691783               32.888565                 3.691783   \n",
       "479            400  3.694067               32.333881                 3.694067   \n",
       "623            300  3.695072               32.788326                 3.695072   \n",
       "1646           400  3.695392               31.876768                 3.695392   \n",
       "1654           400  3.696461               32.876373                 3.696461   \n",
       "1647           400  3.696624               32.634186                 3.696624   \n",
       "632            300  3.699656               32.943523                 3.699656   \n",
       "1500           500  3.699997               33.148014                 3.699997   \n",
       "352            500  3.700149               32.162991                 3.700149   \n",
       "1289           500  3.701254               32.502342                 3.701254   \n",
       "1268           400  3.701380               33.022202                 3.701380   \n",
       "1208           300  3.702021               32.039867                 3.702021   \n",
       "1465           400  3.702948               32.538918                 3.702948   \n",
       "1110           500  3.703192               32.063816                 3.703192   \n",
       "1434           400  3.703836               33.105751                 3.703836   \n",
       "1252           400  3.705340               31.980204                 3.705340   \n",
       "1901           500  3.705462               31.864922                 3.705462   \n",
       "1687           500  3.705805               33.054108                 3.705805   \n",
       "\n",
       "          loss  mean_squared_error  mean_absolute_error activation  \\\n",
       "717   3.351209           28.824132             3.351209       relu   \n",
       "1631  3.439334           33.444127             3.439334       relu   \n",
       "308   3.589276           32.428992             3.589276       relu   \n",
       "479   3.217701           27.858132             3.217701       relu   \n",
       "623   3.756492           34.210275             3.756492       relu   \n",
       "1646  3.624677           31.619041             3.624677       relu   \n",
       "1654  3.756115           34.317944             3.756115       relu   \n",
       "1647  3.470826           31.502185             3.470826       relu   \n",
       "632   3.563812           33.397288             3.563812       relu   \n",
       "1500  3.706141           34.206569             3.706141       relu   \n",
       "352   3.577147           31.404374             3.577147       relu   \n",
       "1289  3.465750           30.054381             3.465750       relu   \n",
       "1268  3.451596           31.207057             3.451596       relu   \n",
       "1208  3.301353           29.459223             3.301353       relu   \n",
       "1465  3.522184           32.084558             3.522184       relu   \n",
       "1110  3.335393           28.492811             3.335393       relu   \n",
       "1434  3.722057           36.172866             3.722057       relu   \n",
       "1252  3.400247           30.965496             3.400247       relu   \n",
       "1901  3.772157           33.234667             3.772157       relu   \n",
       "1687  3.556864           31.799229             3.556864       relu   \n",
       "\n",
       "      batch_size  dropout  epochs  filters_first  filters_second  \\\n",
       "717          200      0.6     500              4              12   \n",
       "1631         256      0.6     400              8              12   \n",
       "308          200      0.3     400             12               8   \n",
       "479          200      0.5     400              8              12   \n",
       "623          200      0.6     300             10              12   \n",
       "1646         256      0.6     400             10              12   \n",
       "1654         256      0.6     400             12               8   \n",
       "1647         256      0.6     400             10              12   \n",
       "632          200      0.6     300             12              10   \n",
       "1500         256      0.5     500              8              12   \n",
       "352          200      0.3     500             10               4   \n",
       "1289         256      0.3     500              4              10   \n",
       "1268         256      0.3     400             12               8   \n",
       "1208         256      0.3     300             12              10   \n",
       "1465         256      0.5     400             12              10   \n",
       "1110         256      0.2     500              8               8   \n",
       "1434         256      0.5     400              8              10   \n",
       "1252         256      0.3     400             10               8   \n",
       "1901         256      0.8     500             10              12   \n",
       "1687         256      0.6     500              8               8   \n",
       "\n",
       "                                            global_pool  kernel_size loss  \\\n",
       "717   <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "1631  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            3  mae   \n",
       "308   <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "479   <class 'keras.layers.pooling.GlobalMaxPooling1D'>            3  mae   \n",
       "623   <class 'keras.layers.pooling.GlobalMaxPooling1D'>            3  mae   \n",
       "1646  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            3  mae   \n",
       "1654  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            3  mae   \n",
       "1647  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            3  mae   \n",
       "632   <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "1500  <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "352   <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "1289  <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "1268  <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "1208  <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "1465  <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "1110  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            3  mae   \n",
       "1434  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            3  mae   \n",
       "1252  <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "1901  <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "1687  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            3  mae   \n",
       "\n",
       "     padding                                          pooling  \n",
       "717     same      <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "1631    same      <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "308     same  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "479     same      <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "623     same      <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "1646    same  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1654    same  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1647    same      <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "632     same  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1500    same  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "352     same  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1289    same      <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "1268    same  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1208    same  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1465    same      <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "1110    same  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1434    same  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1252    same  <class 'keras.layers.pooling.AveragePooling1D'>  \n",
       "1901    same      <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "1687    same      <class 'keras.layers.pooling.MaxPooling1D'>  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cnn2_opt3.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obervations**\n",
    "- using global pooling seems to provide better results than flattening features maps\n",
    "- when using global pooling we should try more epochs\n",
    "- batch size of 200 seems to dominate the best results\n",
    "- dropout rate should be higher than 0.2\n",
    "- the number of filters in the second CNN layer was dominated by 8 and 12\n",
    "- max over-time pooling seems to work a little better than the average over-time pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Round 4:**\n",
    "\n",
    "Goals:\n",
    "- try limiting the number of filters the second layer to 8 and 12.\n",
    "- try a smaller filter kernel size => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters_first':[4, 8, 10, 12],\n",
    "     'filters_second':[8, 12],\n",
    "     'global_pool' : [GlobalMaxPooling1D, GlobalAveragePooling1D],\n",
    "     'pooling' : [MaxPooling1D],\n",
    "     'kernel_size' : [2, 3],\n",
    "     'batch_size': [200],\n",
    "     'epochs': [400, 500, 600],\n",
    "     'dropout': [0.3, 0.4, 0.5, 0.6, 0.8],\n",
    "     'padding' : ['same', ],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 480/480 [1:11:08<00:00, 10.43s/it]\n"
     ]
    }
   ],
   "source": [
    "h_cnn2_opt4 = ta.Scan(x, y, params=p,\n",
    "            model=get_cnn_2l_optimize_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt4 = ta.Reporting(h_cnn2_opt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt4.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}cnn2_opt4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters_first</th>\n",
       "      <th>filters_second</th>\n",
       "      <th>global_pool</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>padding</th>\n",
       "      <th>pooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>400</td>\n",
       "      <td>3.657040</td>\n",
       "      <td>32.612061</td>\n",
       "      <td>3.657040</td>\n",
       "      <td>3.666067</td>\n",
       "      <td>32.771190</td>\n",
       "      <td>3.666067</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>500</td>\n",
       "      <td>3.666194</td>\n",
       "      <td>32.019459</td>\n",
       "      <td>3.666194</td>\n",
       "      <td>3.648907</td>\n",
       "      <td>31.953220</td>\n",
       "      <td>3.648907</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>400</td>\n",
       "      <td>3.679745</td>\n",
       "      <td>32.434525</td>\n",
       "      <td>3.679745</td>\n",
       "      <td>3.650768</td>\n",
       "      <td>33.093451</td>\n",
       "      <td>3.650768</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>600</td>\n",
       "      <td>3.686366</td>\n",
       "      <td>32.982075</td>\n",
       "      <td>3.686366</td>\n",
       "      <td>3.858482</td>\n",
       "      <td>34.156106</td>\n",
       "      <td>3.858482</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>600</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>600</td>\n",
       "      <td>3.686554</td>\n",
       "      <td>32.699501</td>\n",
       "      <td>3.686554</td>\n",
       "      <td>3.849001</td>\n",
       "      <td>33.781052</td>\n",
       "      <td>3.849001</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>600</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>500</td>\n",
       "      <td>3.687132</td>\n",
       "      <td>31.864271</td>\n",
       "      <td>3.687132</td>\n",
       "      <td>3.519705</td>\n",
       "      <td>29.559919</td>\n",
       "      <td>3.519705</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>400</td>\n",
       "      <td>3.688397</td>\n",
       "      <td>32.634480</td>\n",
       "      <td>3.688397</td>\n",
       "      <td>3.512792</td>\n",
       "      <td>30.066487</td>\n",
       "      <td>3.512792</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>600</td>\n",
       "      <td>3.689655</td>\n",
       "      <td>32.604107</td>\n",
       "      <td>3.689655</td>\n",
       "      <td>3.447140</td>\n",
       "      <td>29.515491</td>\n",
       "      <td>3.447140</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>600</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>500</td>\n",
       "      <td>3.690809</td>\n",
       "      <td>32.312889</td>\n",
       "      <td>3.690809</td>\n",
       "      <td>3.445940</td>\n",
       "      <td>29.571715</td>\n",
       "      <td>3.445940</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>500</td>\n",
       "      <td>3.697461</td>\n",
       "      <td>32.308838</td>\n",
       "      <td>3.697461</td>\n",
       "      <td>3.376893</td>\n",
       "      <td>29.633159</td>\n",
       "      <td>3.376893</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>500</td>\n",
       "      <td>3.698622</td>\n",
       "      <td>33.334137</td>\n",
       "      <td>3.698622</td>\n",
       "      <td>4.096041</td>\n",
       "      <td>39.831107</td>\n",
       "      <td>4.096041</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>400</td>\n",
       "      <td>3.698840</td>\n",
       "      <td>31.412342</td>\n",
       "      <td>3.698840</td>\n",
       "      <td>3.128790</td>\n",
       "      <td>26.212668</td>\n",
       "      <td>3.128790</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.4</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>600</td>\n",
       "      <td>3.700423</td>\n",
       "      <td>32.300842</td>\n",
       "      <td>3.700423</td>\n",
       "      <td>3.292824</td>\n",
       "      <td>27.305696</td>\n",
       "      <td>3.292824</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>600</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>500</td>\n",
       "      <td>3.700824</td>\n",
       "      <td>32.650928</td>\n",
       "      <td>3.700824</td>\n",
       "      <td>4.059813</td>\n",
       "      <td>39.746274</td>\n",
       "      <td>4.059813</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>500</td>\n",
       "      <td>3.701893</td>\n",
       "      <td>32.019173</td>\n",
       "      <td>3.701893</td>\n",
       "      <td>3.416602</td>\n",
       "      <td>30.412022</td>\n",
       "      <td>3.416602</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>400</td>\n",
       "      <td>3.706287</td>\n",
       "      <td>32.622047</td>\n",
       "      <td>3.706287</td>\n",
       "      <td>3.581604</td>\n",
       "      <td>32.467934</td>\n",
       "      <td>3.581604</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>500</td>\n",
       "      <td>3.707076</td>\n",
       "      <td>33.567337</td>\n",
       "      <td>3.707076</td>\n",
       "      <td>4.312657</td>\n",
       "      <td>44.575833</td>\n",
       "      <td>4.312657</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.8</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>500</td>\n",
       "      <td>3.710719</td>\n",
       "      <td>32.444405</td>\n",
       "      <td>3.710719</td>\n",
       "      <td>2.956323</td>\n",
       "      <td>24.898494</td>\n",
       "      <td>2.956323</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>3</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>500</td>\n",
       "      <td>3.710785</td>\n",
       "      <td>32.644787</td>\n",
       "      <td>3.710785</td>\n",
       "      <td>3.360139</td>\n",
       "      <td>29.496815</td>\n",
       "      <td>3.360139</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.3</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>500</td>\n",
       "      <td>3.710947</td>\n",
       "      <td>33.190170</td>\n",
       "      <td>3.710947</td>\n",
       "      <td>3.829726</td>\n",
       "      <td>33.069058</td>\n",
       "      <td>3.829726</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.4</td>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "316           400  3.657040               32.612061                 3.657040   \n",
       "234           500  3.666194               32.019459                 3.666194   \n",
       "214           400  3.679745               32.434525                 3.679745   \n",
       "354           600  3.686366               32.982075                 3.686366   \n",
       "366           600  3.686554               32.699501                 3.686554   \n",
       "248           500  3.687132               31.864271                 3.687132   \n",
       "220           400  3.688397               32.634480                 3.688397   \n",
       "280           600  3.689655               32.604107                 3.689655   \n",
       "158           500  3.690809               32.312889                 3.690809   \n",
       "332           500  3.697461               32.308838                 3.697461   \n",
       "344           500  3.698622               33.334137                 3.698622   \n",
       "124           400  3.698840               31.412342                 3.698840   \n",
       "286           600  3.700423               32.300842                 3.700423   \n",
       "338           500  3.700824               32.650928                 3.700824   \n",
       "46            500  3.701893               32.019173                 3.701893   \n",
       "299           400  3.706287               32.622047                 3.706287   \n",
       "417           500  3.707076               33.567337                 3.707076   \n",
       "59            500  3.710719               32.444405                 3.710719   \n",
       "42            500  3.710785               32.644787                 3.710785   \n",
       "152           500  3.710947               33.190170                 3.710947   \n",
       "\n",
       "         loss  mean_squared_error  mean_absolute_error activation  batch_size  \\\n",
       "316  3.666067           32.771190             3.666067       relu         200   \n",
       "234  3.648907           31.953220             3.648907       relu         200   \n",
       "214  3.650768           33.093451             3.650768       relu         200   \n",
       "354  3.858482           34.156106             3.858482       relu         200   \n",
       "366  3.849001           33.781052             3.849001       relu         200   \n",
       "248  3.519705           29.559919             3.519705       relu         200   \n",
       "220  3.512792           30.066487             3.512792       relu         200   \n",
       "280  3.447140           29.515491             3.447140       relu         200   \n",
       "158  3.445940           29.571715             3.445940       relu         200   \n",
       "332  3.376893           29.633159             3.376893       relu         200   \n",
       "344  4.096041           39.831107             4.096041       relu         200   \n",
       "124  3.128790           26.212668             3.128790       relu         200   \n",
       "286  3.292824           27.305696             3.292824       relu         200   \n",
       "338  4.059813           39.746274             4.059813       relu         200   \n",
       "46   3.416602           30.412022             3.416602       relu         200   \n",
       "299  3.581604           32.467934             3.581604       relu         200   \n",
       "417  4.312657           44.575833             4.312657       relu         200   \n",
       "59   2.956323           24.898494             2.956323       relu         200   \n",
       "42   3.360139           29.496815             3.360139       relu         200   \n",
       "152  3.829726           33.069058             3.829726       relu         200   \n",
       "\n",
       "     dropout  epochs  filters_first  filters_second  \\\n",
       "316      0.6     400             12              12   \n",
       "234      0.5     500              8               8   \n",
       "214      0.5     400             10              12   \n",
       "354      0.6     600              4               8   \n",
       "366      0.6     600              8              12   \n",
       "248      0.5     500             12               8   \n",
       "220      0.5     400             12              12   \n",
       "280      0.5     600             12               8   \n",
       "158      0.4     500             12              12   \n",
       "332      0.6     500              8              12   \n",
       "344      0.6     500             12               8   \n",
       "124      0.4     400             12              12   \n",
       "286      0.5     600             12              12   \n",
       "338      0.6     500             10               8   \n",
       "46       0.3     500              8              12   \n",
       "299      0.6     400              8               8   \n",
       "417      0.8     500              4               8   \n",
       "59       0.3     500             12               8   \n",
       "42       0.3     500              8               8   \n",
       "152      0.4     500             12               8   \n",
       "\n",
       "                                           global_pool  kernel_size loss  \\\n",
       "316  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "234  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "214  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "354  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "366  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "248  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "220  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "280  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "158  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "332  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "344  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "124  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "286  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "338  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "46   <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "299  <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "417  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            3  mae   \n",
       "59   <class 'keras.layers.pooling.GlobalAveragePool...            3  mae   \n",
       "42   <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "152  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "\n",
       "    padding                                      pooling  \n",
       "316    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "234    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "214    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "354    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "366    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "248    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "220    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "280    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "158    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "332    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "344    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "124    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "286    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "338    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "46     same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "299    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "417    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "59     same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "42     same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "152    same  <class 'keras.layers.pooling.MaxPooling1D'>  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cnn2_opt4.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- the kernel size 2 seems to work better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Round 5:**\n",
    "\n",
    "Goals:\n",
    "- limit the number of combinations to the most promising ones (the hyperparameters in top 3 configurations)\n",
    "- try adding a dense layer with diffferent dropout rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_2l_optimize_dense_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "    MAX_SEQUENCE_LENGTH = x_train.shape[1]\n",
    "    \n",
    "    global embedding_matrix\n",
    "    \n",
    "    embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                     output_dim=embedding_matrix.shape[1],\n",
    "                     mask_zero=False,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=MAX_SEQUENCE_LENGTH,\n",
    "                     trainable=False)\n",
    "\n",
    "    line_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name=\"input\")\n",
    "    embedded_sequences = embedding_layer(line_input)\n",
    "    cnn = Conv1D(filters=params['filters_first'], kernel_size=params['kernel_size'], strides=1, \n",
    "                        padding=params['padding'],\n",
    "                        activation=params['activation'])(embedded_sequences)\n",
    "    cnn = params['pooling'](pool_size=2)(cnn)\n",
    "    cnn = Conv1D(filters=params['filters_second'], kernel_size=params['kernel_size'], strides=1, \n",
    "                        padding=params['padding'],\n",
    "                        activation=params['activation'])(cnn)\n",
    "    cnn = AveragePooling1D(pool_size=2)(cnn)\n",
    "    \n",
    "    if params['global_pool'] is False or params['global_pool'] is None:\n",
    "        cnn = Flatten()(cnn)\n",
    "\n",
    "    cnn = Dropout(params['dropout'])(cnn)\n",
    "    \n",
    "    if params['global_pool'] is not None:\n",
    "        cnn = params['global_pool']()(cnn)\n",
    "        \n",
    "    dense = Dense(params['dense_additional'], activation='relu')(cnn)\n",
    "    \n",
    "    dense = Dropout(params['dropout2'])(dense)\n",
    "\n",
    "    output = Dense(1, activation='linear')(dense)\n",
    "\n",
    "    model = Model([line_input] , output) \n",
    "    \n",
    "    optimizer = Adam(lr=0.001, beta_1=0.95, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=params['loss'],\n",
    "                  metrics=['mse', 'mae'])\n",
    "\n",
    "    callbacks_list = [\n",
    "        ReduceLROnPlateau( \n",
    "            monitor='loss',\n",
    "            min_lr=0.001,\n",
    "            factor=0.5,\n",
    "            verbose=1,\n",
    "            patience=10), \n",
    "    ]\n",
    "    \n",
    "    out = model.fit(x_train, y_train,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[x_val, y_val])\n",
    "    return out, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters_first':[8, 10, 12],\n",
    "     'filters_second':[8, 12],\n",
    "     'dense_additional':[2, 4, 6, 8, 12],\n",
    "     'global_pool' : [GlobalMaxPooling1D, GlobalAveragePooling1D],\n",
    "     'pooling' : [MaxPooling1D],\n",
    "     'kernel_size' : [2],\n",
    "     'batch_size': [200],\n",
    "     'epochs': [400, 500],\n",
    "     'dropout': [ 0.6, 0.8],\n",
    "     'dropout2': [0.0, 0.2, 0.4, 0.6, 0.8],\n",
    "     'padding' : ['same', ],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1200/1200 [3:02:27<00:00, 11.45s/it]\n"
     ]
    }
   ],
   "source": [
    "h_cnn2_opt5 = ta.Scan(x, y, params=p,\n",
    "            model=get_cnn_2l_optimize_dense_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt5 = ta.Reporting(h_cnn2_opt5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt5.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}cnn2_opt5.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dense_additional</th>\n",
       "      <th>dropout</th>\n",
       "      <th>dropout2</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters_first</th>\n",
       "      <th>filters_second</th>\n",
       "      <th>global_pool</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>padding</th>\n",
       "      <th>pooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>500</td>\n",
       "      <td>3.665074</td>\n",
       "      <td>32.045742</td>\n",
       "      <td>3.665074</td>\n",
       "      <td>3.689064</td>\n",
       "      <td>32.694996</td>\n",
       "      <td>3.689064</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>400</td>\n",
       "      <td>3.665128</td>\n",
       "      <td>31.723003</td>\n",
       "      <td>3.665128</td>\n",
       "      <td>3.296635</td>\n",
       "      <td>30.004530</td>\n",
       "      <td>3.296635</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>12</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>400</td>\n",
       "      <td>3.669019</td>\n",
       "      <td>32.616409</td>\n",
       "      <td>3.669019</td>\n",
       "      <td>3.531558</td>\n",
       "      <td>31.979408</td>\n",
       "      <td>3.531558</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>400</td>\n",
       "      <td>3.674914</td>\n",
       "      <td>33.637676</td>\n",
       "      <td>3.674914</td>\n",
       "      <td>4.104434</td>\n",
       "      <td>38.122835</td>\n",
       "      <td>4.104434</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>12</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>400</td>\n",
       "      <td>3.679839</td>\n",
       "      <td>33.244526</td>\n",
       "      <td>3.679839</td>\n",
       "      <td>3.949038</td>\n",
       "      <td>33.710525</td>\n",
       "      <td>3.949038</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>500</td>\n",
       "      <td>3.680055</td>\n",
       "      <td>30.912025</td>\n",
       "      <td>3.680055</td>\n",
       "      <td>3.131540</td>\n",
       "      <td>27.341768</td>\n",
       "      <td>3.131540</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>400</td>\n",
       "      <td>3.681636</td>\n",
       "      <td>32.106430</td>\n",
       "      <td>3.681636</td>\n",
       "      <td>3.798454</td>\n",
       "      <td>32.427885</td>\n",
       "      <td>3.798454</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>400</td>\n",
       "      <td>3.684298</td>\n",
       "      <td>32.565975</td>\n",
       "      <td>3.684298</td>\n",
       "      <td>3.495869</td>\n",
       "      <td>33.353973</td>\n",
       "      <td>3.495869</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>12</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>400</td>\n",
       "      <td>3.686246</td>\n",
       "      <td>33.235195</td>\n",
       "      <td>3.686246</td>\n",
       "      <td>3.672705</td>\n",
       "      <td>36.881931</td>\n",
       "      <td>3.672705</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>500</td>\n",
       "      <td>3.688753</td>\n",
       "      <td>32.668148</td>\n",
       "      <td>3.688753</td>\n",
       "      <td>3.586621</td>\n",
       "      <td>32.060119</td>\n",
       "      <td>3.586621</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>500</td>\n",
       "      <td>3.691376</td>\n",
       "      <td>32.628555</td>\n",
       "      <td>3.691376</td>\n",
       "      <td>3.389980</td>\n",
       "      <td>29.738721</td>\n",
       "      <td>3.389980</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>400</td>\n",
       "      <td>3.695036</td>\n",
       "      <td>32.220871</td>\n",
       "      <td>3.695036</td>\n",
       "      <td>3.316816</td>\n",
       "      <td>29.395466</td>\n",
       "      <td>3.316816</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>12</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>500</td>\n",
       "      <td>3.696243</td>\n",
       "      <td>31.150700</td>\n",
       "      <td>3.696243</td>\n",
       "      <td>3.145646</td>\n",
       "      <td>26.180348</td>\n",
       "      <td>3.145646</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>400</td>\n",
       "      <td>3.697621</td>\n",
       "      <td>33.037952</td>\n",
       "      <td>3.697621</td>\n",
       "      <td>3.621639</td>\n",
       "      <td>32.663410</td>\n",
       "      <td>3.621639</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>500</td>\n",
       "      <td>3.698588</td>\n",
       "      <td>34.033016</td>\n",
       "      <td>3.698588</td>\n",
       "      <td>4.227581</td>\n",
       "      <td>37.799930</td>\n",
       "      <td>4.227581</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>400</td>\n",
       "      <td>3.699306</td>\n",
       "      <td>32.494976</td>\n",
       "      <td>3.699306</td>\n",
       "      <td>3.302817</td>\n",
       "      <td>28.560182</td>\n",
       "      <td>3.302817</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>400</td>\n",
       "      <td>3.699588</td>\n",
       "      <td>32.162037</td>\n",
       "      <td>3.699588</td>\n",
       "      <td>3.284139</td>\n",
       "      <td>26.681428</td>\n",
       "      <td>3.284139</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>400</td>\n",
       "      <td>3.704071</td>\n",
       "      <td>32.658562</td>\n",
       "      <td>3.704071</td>\n",
       "      <td>3.381835</td>\n",
       "      <td>27.870600</td>\n",
       "      <td>3.381835</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>12</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>400</td>\n",
       "      <td>3.706937</td>\n",
       "      <td>32.963989</td>\n",
       "      <td>3.706937</td>\n",
       "      <td>3.993799</td>\n",
       "      <td>35.462674</td>\n",
       "      <td>3.993799</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>400</td>\n",
       "      <td>3.710156</td>\n",
       "      <td>32.507229</td>\n",
       "      <td>3.710156</td>\n",
       "      <td>3.106636</td>\n",
       "      <td>24.497462</td>\n",
       "      <td>3.106636</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "733            500  3.665074               32.045742                 3.665074   \n",
       "961            400  3.665128               31.723003                 3.665128   \n",
       "243            400  3.669019               32.616409                 3.669019   \n",
       "1139           400  3.674914               33.637676                 3.674914   \n",
       "275            400  3.679839               33.244526                 3.679839   \n",
       "501            500  3.680055               30.912025                 3.680055   \n",
       "749            400  3.681636               32.106430                 3.681636   \n",
       "1011           400  3.684298               32.565975                 3.684298   \n",
       "721            400  3.686246               33.235195                 3.686246   \n",
       "263            500  3.688753               32.668148                 3.688753   \n",
       "257            500  3.691376               32.628555                 3.691376   \n",
       "963            400  3.695036               32.220871                 3.695036   \n",
       "735            500  3.696243               31.150700                 3.696243   \n",
       "723            400  3.697621               33.037952                 3.697621   \n",
       "41             500  3.698588               34.033016                 3.698588   \n",
       "247            400  3.699306               32.494976                 3.699306   \n",
       "727            400  3.699588               32.162037                 3.699588   \n",
       "1111           400  3.704071               32.658562                 3.704071   \n",
       "753            400  3.706937               32.963989                 3.706937   \n",
       "491            400  3.710156               32.507229                 3.710156   \n",
       "\n",
       "          loss  mean_squared_error  mean_absolute_error activation  \\\n",
       "733   3.689064           32.694996             3.689064       relu   \n",
       "961   3.296635           30.004530             3.296635       relu   \n",
       "243   3.531558           31.979408             3.531558       relu   \n",
       "1139  4.104434           38.122835             4.104434       relu   \n",
       "275   3.949038           33.710525             3.949038       relu   \n",
       "501   3.131540           27.341768             3.131540       relu   \n",
       "749   3.798454           32.427885             3.798454       relu   \n",
       "1011  3.495869           33.353973             3.495869       relu   \n",
       "721   3.672705           36.881931             3.672705       relu   \n",
       "263   3.586621           32.060119             3.586621       relu   \n",
       "257   3.389980           29.738721             3.389980       relu   \n",
       "963   3.316816           29.395466             3.316816       relu   \n",
       "735   3.145646           26.180348             3.145646       relu   \n",
       "723   3.621639           32.663410             3.621639       relu   \n",
       "41    4.227581           37.799930             4.227581       relu   \n",
       "247   3.302817           28.560182             3.302817       relu   \n",
       "727   3.284139           26.681428             3.284139       relu   \n",
       "1111  3.381835           27.870600             3.381835       relu   \n",
       "753   3.993799           35.462674             3.993799       relu   \n",
       "491   3.106636           24.497462             3.106636       relu   \n",
       "\n",
       "      batch_size  dense_additional  dropout  dropout2  epochs  filters_first  \\\n",
       "733          200                 8      0.6       0.0     500              8   \n",
       "961          200                12      0.6       0.0     400              8   \n",
       "243          200                 4      0.6       0.0     400              8   \n",
       "1139         200                12      0.8       0.4     400             12   \n",
       "275          200                 4      0.6       0.2     400             12   \n",
       "501          200                 6      0.6       0.0     500             12   \n",
       "749          200                 8      0.6       0.2     400             10   \n",
       "1011         200                12      0.6       0.4     400              8   \n",
       "721          200                 8      0.6       0.0     400              8   \n",
       "263          200                 4      0.6       0.0     500             12   \n",
       "257          200                 4      0.6       0.0     500             10   \n",
       "963          200                12      0.6       0.0     400              8   \n",
       "735          200                 8      0.6       0.0     500              8   \n",
       "723          200                 8      0.6       0.0     400              8   \n",
       "41           200                 2      0.6       0.2     500             10   \n",
       "247          200                 4      0.6       0.0     400             10   \n",
       "727          200                 8      0.6       0.0     400             10   \n",
       "1111         200                12      0.8       0.2     400             10   \n",
       "753          200                 8      0.6       0.2     400             12   \n",
       "491          200                 6      0.6       0.0     400             12   \n",
       "\n",
       "      filters_second                                        global_pool  \\\n",
       "733                8  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "961                8  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "243               12  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "1139              12  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "275               12  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "501                8  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "749                8  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "1011              12  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "721                8  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "263               12  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "257                8  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "963               12  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "735               12  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "723               12  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "41                 8  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "247               12  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "727               12  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "1111              12  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "753                8  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "491               12  <class 'keras.layers.pooling.GlobalAveragePool...   \n",
       "\n",
       "      kernel_size loss padding                                      pooling  \n",
       "733             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "961             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "243             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "1139            2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "275             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "501             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "749             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "1011            2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "721             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "263             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "257             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "963             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "735             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "723             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "41              2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "247             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "727             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "1111            2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "753             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "491             2  mae    same  <class 'keras.layers.pooling.MaxPooling1D'>  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cnn2_opt5.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- adding a dense layer did not improve the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Take top 3 configurations from the round 4 and study their stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Configuration 1:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters_first':[12],\n",
    "     'filters_second':[12],\n",
    "     'global_pool' : [GlobalMaxPooling1D],\n",
    "     'pooling' : [MaxPooling1D],\n",
    "     'kernel_size' : [2],\n",
    "     'batch_size': [200, ] * 10,\n",
    "     'epochs': [400],\n",
    "     'dropout': [0.6],\n",
    "     'padding' : ['same', ],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:07<00:00,  6.68s/it]\n"
     ]
    }
   ],
   "source": [
    "h_cnn2_opt4_c1 = ta.Scan(x, y, params=p,\n",
    "            model=get_cnn_2l_optimize_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt4_c1 = ta.Reporting(h_cnn2_opt4_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt4_c1.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}cnn2_opt4_c1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters_first</th>\n",
       "      <th>filters_second</th>\n",
       "      <th>global_pool</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>padding</th>\n",
       "      <th>pooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>3.690124</td>\n",
       "      <td>32.149601</td>\n",
       "      <td>3.690124</td>\n",
       "      <td>3.926525</td>\n",
       "      <td>32.113115</td>\n",
       "      <td>3.926525</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>400</td>\n",
       "      <td>3.702460</td>\n",
       "      <td>32.360439</td>\n",
       "      <td>3.702460</td>\n",
       "      <td>3.802073</td>\n",
       "      <td>34.589403</td>\n",
       "      <td>3.802073</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400</td>\n",
       "      <td>3.709958</td>\n",
       "      <td>33.145634</td>\n",
       "      <td>3.709958</td>\n",
       "      <td>3.741108</td>\n",
       "      <td>33.907757</td>\n",
       "      <td>3.741108</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>3.710782</td>\n",
       "      <td>32.722908</td>\n",
       "      <td>3.710782</td>\n",
       "      <td>3.763648</td>\n",
       "      <td>35.922882</td>\n",
       "      <td>3.763648</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400</td>\n",
       "      <td>3.744325</td>\n",
       "      <td>33.906372</td>\n",
       "      <td>3.744325</td>\n",
       "      <td>4.014873</td>\n",
       "      <td>34.123041</td>\n",
       "      <td>4.014873</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>400</td>\n",
       "      <td>3.746644</td>\n",
       "      <td>33.665012</td>\n",
       "      <td>3.746644</td>\n",
       "      <td>3.811208</td>\n",
       "      <td>35.135997</td>\n",
       "      <td>3.811208</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>3.749992</td>\n",
       "      <td>33.479336</td>\n",
       "      <td>3.749992</td>\n",
       "      <td>3.940854</td>\n",
       "      <td>35.305391</td>\n",
       "      <td>3.940854</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>400</td>\n",
       "      <td>3.767886</td>\n",
       "      <td>32.530029</td>\n",
       "      <td>3.767886</td>\n",
       "      <td>3.402078</td>\n",
       "      <td>29.189157</td>\n",
       "      <td>3.402078</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>3.807490</td>\n",
       "      <td>35.004692</td>\n",
       "      <td>3.807490</td>\n",
       "      <td>4.096201</td>\n",
       "      <td>39.446648</td>\n",
       "      <td>4.096201</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>3.827899</td>\n",
       "      <td>34.545090</td>\n",
       "      <td>3.827899</td>\n",
       "      <td>3.758857</td>\n",
       "      <td>33.807755</td>\n",
       "      <td>3.758857</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.6</td>\n",
       "      <td>400</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalMaxPooling1D'&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "4           400  3.690124               32.149601                 3.690124   \n",
       "9           400  3.702460               32.360439                 3.702460   \n",
       "6           400  3.709958               33.145634                 3.709958   \n",
       "0           400  3.710782               32.722908                 3.710782   \n",
       "7           400  3.744325               33.906372                 3.744325   \n",
       "8           400  3.746644               33.665012                 3.746644   \n",
       "1           400  3.749992               33.479336                 3.749992   \n",
       "5           400  3.767886               32.530029                 3.767886   \n",
       "3           400  3.807490               35.004692                 3.807490   \n",
       "2           400  3.827899               34.545090                 3.827899   \n",
       "\n",
       "       loss  mean_squared_error  mean_absolute_error activation  batch_size  \\\n",
       "4  3.926525           32.113115             3.926525       relu         200   \n",
       "9  3.802073           34.589403             3.802073       relu         200   \n",
       "6  3.741108           33.907757             3.741108       relu         200   \n",
       "0  3.763648           35.922882             3.763648       relu         200   \n",
       "7  4.014873           34.123041             4.014873       relu         200   \n",
       "8  3.811208           35.135997             3.811208       relu         200   \n",
       "1  3.940854           35.305391             3.940854       relu         200   \n",
       "5  3.402078           29.189157             3.402078       relu         200   \n",
       "3  4.096201           39.446648             4.096201       relu         200   \n",
       "2  3.758857           33.807755             3.758857       relu         200   \n",
       "\n",
       "   dropout  epochs  filters_first  filters_second  \\\n",
       "4      0.6     400             12              12   \n",
       "9      0.6     400             12              12   \n",
       "6      0.6     400             12              12   \n",
       "0      0.6     400             12              12   \n",
       "7      0.6     400             12              12   \n",
       "8      0.6     400             12              12   \n",
       "1      0.6     400             12              12   \n",
       "5      0.6     400             12              12   \n",
       "3      0.6     400             12              12   \n",
       "2      0.6     400             12              12   \n",
       "\n",
       "                                         global_pool  kernel_size loss  \\\n",
       "4  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "9  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "6  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "0  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "7  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "8  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "1  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "5  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "3  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "2  <class 'keras.layers.pooling.GlobalMaxPooling1D'>            2  mae   \n",
       "\n",
       "  padding                                      pooling  \n",
       "4    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "9    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "6    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "0    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "7    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "8    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "1    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "5    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "3    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "2    same  <class 'keras.layers.pooling.MaxPooling1D'>  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cnn2_opt4_c1.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAE = 3.7457560300827026, SD = 0.045391303236238946'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"MAE = {r_cnn2_opt4_c1.data['val_mean_absolute_error'].mean()}, SD = {r_cnn2_opt4_c1.data['val_mean_absolute_error'].std()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Configuration 2:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters_first':[8],\n",
    "     'filters_second':[8],\n",
    "     'global_pool' : [GlobalAveragePooling1D],\n",
    "     'pooling' : [MaxPooling1D],\n",
    "     'kernel_size' : [2],\n",
    "     'batch_size': [200, ] * 10,\n",
    "     'epochs': [500],\n",
    "     'dropout': [0.5],\n",
    "     'padding' : ['same', ],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:30<00:00,  9.91s/it]\n"
     ]
    }
   ],
   "source": [
    "h_cnn2_opt4_c2 = ta.Scan(x, y, params=p,\n",
    "            model=get_cnn_2l_optimize_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt4_c2 = ta.Reporting(h_cnn2_opt4_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt4_c2.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}cnn2_opt4_c2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters_first</th>\n",
       "      <th>filters_second</th>\n",
       "      <th>global_pool</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>padding</th>\n",
       "      <th>pooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>3.719345</td>\n",
       "      <td>33.121586</td>\n",
       "      <td>3.719345</td>\n",
       "      <td>3.540832</td>\n",
       "      <td>30.583073</td>\n",
       "      <td>3.540832</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>3.719612</td>\n",
       "      <td>32.951797</td>\n",
       "      <td>3.719612</td>\n",
       "      <td>3.814876</td>\n",
       "      <td>35.331375</td>\n",
       "      <td>3.814876</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500</td>\n",
       "      <td>3.740511</td>\n",
       "      <td>32.939259</td>\n",
       "      <td>3.740511</td>\n",
       "      <td>3.653520</td>\n",
       "      <td>35.264673</td>\n",
       "      <td>3.653520</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>3.769524</td>\n",
       "      <td>33.749458</td>\n",
       "      <td>3.769524</td>\n",
       "      <td>3.598128</td>\n",
       "      <td>32.265414</td>\n",
       "      <td>3.598128</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>3.782636</td>\n",
       "      <td>33.586391</td>\n",
       "      <td>3.782636</td>\n",
       "      <td>3.881434</td>\n",
       "      <td>35.740713</td>\n",
       "      <td>3.881434</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500</td>\n",
       "      <td>3.791534</td>\n",
       "      <td>34.250134</td>\n",
       "      <td>3.791534</td>\n",
       "      <td>3.855863</td>\n",
       "      <td>35.348539</td>\n",
       "      <td>3.855863</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>3.794688</td>\n",
       "      <td>34.080273</td>\n",
       "      <td>3.794688</td>\n",
       "      <td>3.924745</td>\n",
       "      <td>35.281860</td>\n",
       "      <td>3.924745</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>3.795801</td>\n",
       "      <td>34.244808</td>\n",
       "      <td>3.795801</td>\n",
       "      <td>3.802575</td>\n",
       "      <td>34.668557</td>\n",
       "      <td>3.802575</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500</td>\n",
       "      <td>3.797349</td>\n",
       "      <td>34.398350</td>\n",
       "      <td>3.797349</td>\n",
       "      <td>3.864193</td>\n",
       "      <td>34.872240</td>\n",
       "      <td>3.864193</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500</td>\n",
       "      <td>3.894730</td>\n",
       "      <td>36.722530</td>\n",
       "      <td>3.894730</td>\n",
       "      <td>4.364989</td>\n",
       "      <td>42.750916</td>\n",
       "      <td>4.364989</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "3           500  3.719345               33.121586                 3.719345   \n",
       "5           500  3.719612               32.951797                 3.719612   \n",
       "6           500  3.740511               32.939259                 3.740511   \n",
       "0           500  3.769524               33.749458                 3.769524   \n",
       "4           500  3.782636               33.586391                 3.782636   \n",
       "9           500  3.791534               34.250134                 3.791534   \n",
       "2           500  3.794688               34.080273                 3.794688   \n",
       "1           500  3.795801               34.244808                 3.795801   \n",
       "8           500  3.797349               34.398350                 3.797349   \n",
       "7           500  3.894730               36.722530                 3.894730   \n",
       "\n",
       "       loss  mean_squared_error  mean_absolute_error activation  batch_size  \\\n",
       "3  3.540832           30.583073             3.540832       relu         200   \n",
       "5  3.814876           35.331375             3.814876       relu         200   \n",
       "6  3.653520           35.264673             3.653520       relu         200   \n",
       "0  3.598128           32.265414             3.598128       relu         200   \n",
       "4  3.881434           35.740713             3.881434       relu         200   \n",
       "9  3.855863           35.348539             3.855863       relu         200   \n",
       "2  3.924745           35.281860             3.924745       relu         200   \n",
       "1  3.802575           34.668557             3.802575       relu         200   \n",
       "8  3.864193           34.872240             3.864193       relu         200   \n",
       "7  4.364989           42.750916             4.364989       relu         200   \n",
       "\n",
       "   dropout  epochs  filters_first  filters_second  \\\n",
       "3      0.5     500              8               8   \n",
       "5      0.5     500              8               8   \n",
       "6      0.5     500              8               8   \n",
       "0      0.5     500              8               8   \n",
       "4      0.5     500              8               8   \n",
       "9      0.5     500              8               8   \n",
       "2      0.5     500              8               8   \n",
       "1      0.5     500              8               8   \n",
       "8      0.5     500              8               8   \n",
       "7      0.5     500              8               8   \n",
       "\n",
       "                                         global_pool  kernel_size loss  \\\n",
       "3  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "5  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "6  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "0  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "4  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "9  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "2  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "1  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "8  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "7  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "\n",
       "  padding                                      pooling  \n",
       "3    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "5    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "6    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "0    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "4    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "9    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "2    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "1    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "8    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "7    same  <class 'keras.layers.pooling.MaxPooling1D'>  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cnn2_opt4_c2.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAE = 3.780572843551636, SD = 0.050619414154958145'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"MAE = {r_cnn2_opt4_c2.data['val_mean_absolute_error'].mean()}, SD = {r_cnn2_opt4_c2.data['val_mean_absolute_error'].std()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Configuration 3:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'filters_first':[10],\n",
    "     'filters_second':[12],\n",
    "     'global_pool' : [GlobalAveragePooling1D],\n",
    "     'pooling' : [MaxPooling1D],\n",
    "     'kernel_size' : [2],\n",
    "     'batch_size': [200, ] * 10,\n",
    "     'epochs': [400],\n",
    "     'dropout': [0.5],\n",
    "     'padding' : ['same', ],\n",
    "     'loss': ['mae',],\n",
    "     'activation':['relu',]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:16<00:00,  7.40s/it]\n"
     ]
    }
   ],
   "source": [
    "h_cnn2_opt4_c3 = ta.Scan(x, y, params=p,\n",
    "            model=get_cnn_2l_optimize_model,\n",
    "            experiment_name='1',\n",
    "            seed = random_seed,\n",
    "            val_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt4_c3 = ta.Reporting(h_cnn2_opt4_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cnn2_opt4_c3.data.sort_values('val_mean_absolute_error').to_excel(f'{output_folder}cnn2_opt4_c3.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mean_squared_error</th>\n",
       "      <th>val_mean_absolute_error</th>\n",
       "      <th>loss</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>filters_first</th>\n",
       "      <th>filters_second</th>\n",
       "      <th>global_pool</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>padding</th>\n",
       "      <th>pooling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>400</td>\n",
       "      <td>3.700188</td>\n",
       "      <td>32.668411</td>\n",
       "      <td>3.700188</td>\n",
       "      <td>3.649286</td>\n",
       "      <td>32.675564</td>\n",
       "      <td>3.649286</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400</td>\n",
       "      <td>3.704947</td>\n",
       "      <td>31.993299</td>\n",
       "      <td>3.704947</td>\n",
       "      <td>3.545169</td>\n",
       "      <td>31.408194</td>\n",
       "      <td>3.545169</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>400</td>\n",
       "      <td>3.714174</td>\n",
       "      <td>31.933207</td>\n",
       "      <td>3.714174</td>\n",
       "      <td>3.324685</td>\n",
       "      <td>29.715143</td>\n",
       "      <td>3.324685</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>3.727131</td>\n",
       "      <td>33.173229</td>\n",
       "      <td>3.727131</td>\n",
       "      <td>3.438814</td>\n",
       "      <td>28.634687</td>\n",
       "      <td>3.438814</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>400</td>\n",
       "      <td>3.735837</td>\n",
       "      <td>33.479610</td>\n",
       "      <td>3.735837</td>\n",
       "      <td>3.802303</td>\n",
       "      <td>35.158085</td>\n",
       "      <td>3.802303</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>400</td>\n",
       "      <td>3.755699</td>\n",
       "      <td>32.398083</td>\n",
       "      <td>3.755699</td>\n",
       "      <td>3.521478</td>\n",
       "      <td>32.818443</td>\n",
       "      <td>3.521478</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>3.769074</td>\n",
       "      <td>33.469788</td>\n",
       "      <td>3.769074</td>\n",
       "      <td>3.986706</td>\n",
       "      <td>34.180003</td>\n",
       "      <td>3.986706</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>3.772059</td>\n",
       "      <td>34.081093</td>\n",
       "      <td>3.772059</td>\n",
       "      <td>3.741108</td>\n",
       "      <td>33.769911</td>\n",
       "      <td>3.741108</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400</td>\n",
       "      <td>3.774521</td>\n",
       "      <td>33.920952</td>\n",
       "      <td>3.774521</td>\n",
       "      <td>3.942487</td>\n",
       "      <td>33.767837</td>\n",
       "      <td>3.942487</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>3.780445</td>\n",
       "      <td>33.447956</td>\n",
       "      <td>3.780445</td>\n",
       "      <td>3.686458</td>\n",
       "      <td>33.487981</td>\n",
       "      <td>3.686458</td>\n",
       "      <td>relu</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.GlobalAveragePool...</td>\n",
       "      <td>2</td>\n",
       "      <td>mae</td>\n",
       "      <td>same</td>\n",
       "      <td>&lt;class 'keras.layers.pooling.MaxPooling1D'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round_epochs  val_loss  val_mean_squared_error  val_mean_absolute_error  \\\n",
       "0           400  3.700188               32.668411                 3.700188   \n",
       "6           400  3.704947               31.993299                 3.704947   \n",
       "5           400  3.714174               31.933207                 3.714174   \n",
       "1           400  3.727131               33.173229                 3.727131   \n",
       "8           400  3.735837               33.479610                 3.735837   \n",
       "9           400  3.755699               32.398083                 3.755699   \n",
       "4           400  3.769074               33.469788                 3.769074   \n",
       "2           400  3.772059               34.081093                 3.772059   \n",
       "7           400  3.774521               33.920952                 3.774521   \n",
       "3           400  3.780445               33.447956                 3.780445   \n",
       "\n",
       "       loss  mean_squared_error  mean_absolute_error activation  batch_size  \\\n",
       "0  3.649286           32.675564             3.649286       relu         200   \n",
       "6  3.545169           31.408194             3.545169       relu         200   \n",
       "5  3.324685           29.715143             3.324685       relu         200   \n",
       "1  3.438814           28.634687             3.438814       relu         200   \n",
       "8  3.802303           35.158085             3.802303       relu         200   \n",
       "9  3.521478           32.818443             3.521478       relu         200   \n",
       "4  3.986706           34.180003             3.986706       relu         200   \n",
       "2  3.741108           33.769911             3.741108       relu         200   \n",
       "7  3.942487           33.767837             3.942487       relu         200   \n",
       "3  3.686458           33.487981             3.686458       relu         200   \n",
       "\n",
       "   dropout  epochs  filters_first  filters_second  \\\n",
       "0      0.5     400             10              12   \n",
       "6      0.5     400             10              12   \n",
       "5      0.5     400             10              12   \n",
       "1      0.5     400             10              12   \n",
       "8      0.5     400             10              12   \n",
       "9      0.5     400             10              12   \n",
       "4      0.5     400             10              12   \n",
       "2      0.5     400             10              12   \n",
       "7      0.5     400             10              12   \n",
       "3      0.5     400             10              12   \n",
       "\n",
       "                                         global_pool  kernel_size loss  \\\n",
       "0  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "6  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "5  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "1  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "8  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "9  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "4  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "2  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "7  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "3  <class 'keras.layers.pooling.GlobalAveragePool...            2  mae   \n",
       "\n",
       "  padding                                      pooling  \n",
       "0    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "6    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "5    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "1    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "8    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "9    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "4    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "2    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "7    same  <class 'keras.layers.pooling.MaxPooling1D'>  \n",
       "3    same  <class 'keras.layers.pooling.MaxPooling1D'>  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cnn2_opt4_c3.data.sort_values('val_mean_absolute_error').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MAE = 3.743407416343689, SD = 0.03072201819838168'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"MAE = {r_cnn2_opt4_c3.data['val_mean_absolute_error'].mean()}, SD = {r_cnn2_opt4_c3.data['val_mean_absolute_error'].std()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "Configuration no. 3 provides the most promising results (the lowest average MAE and the lowest variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 ML-GPU",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
